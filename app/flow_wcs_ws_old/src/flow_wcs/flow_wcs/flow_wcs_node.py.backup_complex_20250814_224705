#!/usr/bin/env python3
"""
Flow WCS Node - Main ROS 2 node for executing linear workflows
"""

import rclpy
from rclpy.node import Node
from rclpy.qos import QoSProfile, ReliabilityPolicy, HistoryPolicy
import yaml
import json
import os
from pathlib import Path
from typing import Dict, Any, List, Optional
from datetime import datetime
import asyncio
from concurrent.futures import ThreadPoolExecutor

from std_msgs.msg import String, Bool
# Remove db_proxy_interfaces import as we're using direct database access
# from db_proxy_interfaces.srv import ExecuteSQL, QueryDatabase


class FlowWCSNode(Node):
    """Main Flow WCS ROS 2 Node for executing linear workflows"""
    
    def __init__(self):
        super().__init__('flow_wcs_node')
        
        # Node parameters
        self.declare_parameter('flows_dir', '/app/config/wcs/flows')
        self.declare_parameter('scan_interval', 5.0)  # seconds
        self.declare_parameter('max_parallel_flows', 10)
        self.declare_parameter('debug_mode', False)
        
        # Get parameters
        self.flows_dir = Path(self.get_parameter('flows_dir').value)
        self.scan_interval = self.get_parameter('scan_interval').value
        self.max_parallel_flows = self.get_parameter('max_parallel_flows').value
        self.debug_mode = self.get_parameter('debug_mode').value
        
        # Flow management
        self.loaded_flows = {}
        self.active_executions = {}
        self.flow_contexts = {}
        self.executor = ThreadPoolExecutor(max_workers=self.max_parallel_flows)
        
        # ROS 2 interfaces
        self.setup_ros_interfaces()
        
        # Start flow scanning
        self.create_timer(self.scan_interval, self.scan_and_execute_flows)
        
        self.get_logger().info(f"Flow WCS Node started - monitoring {self.flows_dir}")
        
    def setup_ros_interfaces(self):
        """Setup ROS 2 publishers, subscribers and service clients"""
        # QoS profile for reliable communication
        qos = QoSProfile(
            reliability=ReliabilityPolicy.RELIABLE,
            history=HistoryPolicy.KEEP_LAST,
            depth=10
        )
        
        # Publishers
        self.flow_status_pub = self.create_publisher(
            String, 'flow_wcs/status', qos)
        self.flow_event_pub = self.create_publisher(
            String, 'flow_wcs/events', qos)
        
        # Subscribers
        self.flow_trigger_sub = self.create_subscription(
            String, 'flow_wcs/trigger', 
            self.handle_flow_trigger, qos)
        
        # Service clients - commented out as we use direct database access
        # self.db_query_client = self.create_client(
        #     QueryDatabase, 'query_database')
        # self.db_execute_client = self.create_client(
        #     ExecuteSQL, 'execute_sql')
    
    def scan_and_execute_flows(self):
        """Scan flows directory and execute enabled flows"""
        if not self.flows_dir.exists():
            self.get_logger().warning(f"Flows directory not found: {self.flows_dir}")
            return
        
        # Load all YAML files
        for flow_file in self.flows_dir.glob("*.yaml"):
            try:
                self.load_flow(flow_file)
            except Exception as e:
                self.get_logger().error(f"Failed to load flow {flow_file}: {e}")
        
        # Execute enabled flows
        for flow_id, flow_data in self.loaded_flows.items():
            if flow_data['flow'].get('enabled', True):
                if flow_id not in self.active_executions:
                    self.execute_flow(flow_id, flow_data)
    
    def load_flow(self, flow_file: Path):
        """Load a flow from YAML file"""
        with open(flow_file, 'r', encoding='utf-8') as f:
            flow_data = yaml.safe_load(f)
        
        # Validate flow structure
        if not self.validate_flow(flow_data):
            self.get_logger().error(f"Invalid flow structure: {flow_file}")
            return
        
        flow_id = flow_data['flow']['id']
        self.loaded_flows[flow_id] = flow_data
        
        if self.debug_mode:
            self.get_logger().info(f"Loaded flow: {flow_id} from {flow_file.name}")
    
    def validate_flow(self, flow_data: Dict) -> bool:
        """Validate flow structure"""
        required_keys = ['meta', 'flow', 'workflow']
        
        # Check top-level structure
        for key in required_keys:
            if key not in flow_data:
                return False
        
        # Check meta section
        if flow_data['meta'].get('system') != 'linear_flow_v2':
            return False
        
        # Check flow section
        if 'id' not in flow_data['flow']:
            return False
        
        # Check workflow sections
        if not isinstance(flow_data['workflow'], list):
            return False
        
        return True
    
    def execute_flow(self, flow_id: str, flow_data: Dict):
        """Execute a flow asynchronously"""
        if flow_id in self.active_executions:
            return  # Already executing
        
        # Create execution context
        context = self.create_flow_context(flow_id, flow_data)
        self.flow_contexts[flow_id] = context
        
        # Submit to executor
        future = self.executor.submit(self.run_flow_workflow, flow_id, flow_data, context)
        self.active_executions[flow_id] = future
        
        # Publish status
        self.publish_flow_status(flow_id, 'started')
    
    def create_flow_context(self, flow_id: str, flow_data: Dict) -> Dict:
        """Create execution context for a flow"""
        return {
            'flow_id': flow_id,
            'work_id': flow_data['flow'].get('work_id'),
            'start_time': datetime.now(),
            'variables': {},
            'current_section': None,
            'current_step': None,
            'status': 'running',
            'errors': []
        }
    
    def run_flow_workflow(self, flow_id: str, flow_data: Dict, context: Dict):
        """Run the workflow sections of a flow"""
        try:
            workflow = flow_data['workflow']
            
            for section in workflow:
                context['current_section'] = section.get('section', 'unnamed')
                
                # Check section condition
                if not self.check_condition(section.get('condition'), context):
                    if self.debug_mode:
                        self.get_logger().info(f"Skipping section: {context['current_section']}")
                    continue
                
                # Execute section steps
                self.execute_section(section, context)
                
                # Check if flow should stop
                if context['status'] == 'stopped':
                    break
            
            # Mark as completed
            context['status'] = 'completed'
            self.publish_flow_status(flow_id, 'completed')
            
        except Exception as e:
            context['status'] = 'error'
            context['errors'].append(str(e))
            self.get_logger().error(f"Flow {flow_id} failed: {e}")
            self.publish_flow_status(flow_id, 'error', str(e))
        
        finally:
            # Clean up
            if flow_id in self.active_executions:
                del self.active_executions[flow_id]
    
    def execute_section(self, section: Dict, context: Dict):
        """Execute a workflow section"""
        steps = section.get('steps', [])
        
        for step in steps:
            context['current_step'] = step.get('id', 'unnamed')
            
            # Skip if condition
            if step.get('skip_if') and self.evaluate_condition(step['skip_if'], context):
                continue
            
            # Execute step based on type
            step_type = step.get('exec', '').split('.')[0]
            
            if step_type == 'query':
                self.execute_query_step(step, context)
            elif step_type == 'check':
                self.execute_check_step(step, context)
            elif step_type == 'task':
                self.execute_task_step(step, context)
            elif step_type == 'foreach':
                self.execute_foreach_step(step, context)
            elif step_type == 'parallel':
                self.execute_parallel_step(step, context)
            else:
                self.get_logger().warning(f"Unknown step type: {step_type}")
    
    def execute_query_step(self, step: Dict, context: Dict):
        """Execute a database query step"""
        exec_parts = step['exec'].split('.')
        query_type = exec_parts[1] if len(exec_parts) > 1 else 'select'
        
        # Build query based on parameters
        params = step.get('params', {})
        
        if query_type == 'locations':
            query = self.build_location_query(params)
        elif query_type == 'racks':
            query = self.build_rack_query(params)
        else:
            query = params.get('query', '')
        
        # Execute query
        result = self.execute_database_query(query)
        
        # Store result
        if 'store' in step:
            context['variables'][step['store']] = result
    
    def execute_check_step(self, step: Dict, context: Dict):
        """Execute a check/condition step"""
        exec_parts = step['exec'].split('.')
        check_type = exec_parts[1] if len(exec_parts) > 1 else 'condition'
        
        params = step.get('params', {})
        
        # Perform check based on type
        if check_type == 'rack_status':
            result = self.check_rack_status(params, context)
        elif check_type == 'task_exists':
            result = self.check_task_exists(params, context)
        else:
            result = False
        
        # Store result
        if 'store' in step:
            context['variables'][step['store']] = result
    
    def execute_task_step(self, step: Dict, context: Dict):
        """Execute a task creation step"""
        params = step.get('params', {})
        
        # Resolve variables in parameters
        resolved_params = self.resolve_variables(params, context)
        
        # Create task
        task_id = self.create_agv_task(resolved_params, context)
        
        # Store task ID
        if 'store' in step:
            context['variables'][step['store']] = task_id
    
    def execute_foreach_step(self, step: Dict, context: Dict):
        """Execute a foreach loop step"""
        items_var = step.get('items', '')
        items = self.resolve_variable(items_var, context)
        
        if not isinstance(items, list):
            return
        
        sub_steps = step.get('steps', [])
        
        for item in items:
            # Create sub-context
            sub_context = context.copy()
            sub_context['variables']['_item'] = item
            
            # Execute sub-steps
            for sub_step in sub_steps:
                self.execute_section({'steps': [sub_step]}, sub_context)
    
    def execute_parallel_step(self, step: Dict, context: Dict):
        """Execute parallel branches"""
        branches = step.get('branches', [])
        
        # Execute branches in parallel (simplified for now)
        for branch in branches:
            sub_steps = branch.get('steps', [])
            for sub_step in sub_steps:
                self.execute_section({'steps': [sub_step]}, context)
    
    def check_condition(self, condition: Any, context: Dict) -> bool:
        """Check if a condition is met"""
        if condition is None:
            return True
        
        if isinstance(condition, str):
            return self.evaluate_condition(condition, context)
        
        if isinstance(condition, dict):
            # Complex condition evaluation
            return True  # Simplified for now
        
        return bool(condition)
    
    def evaluate_condition(self, condition: str, context: Dict) -> bool:
        """Evaluate a condition expression"""
        # Simple variable resolution
        if condition.startswith('${') and condition.endswith('}'):
            var_name = condition[2:-1]
            return bool(context['variables'].get(var_name))
        
        # Direct boolean
        return condition.lower() == 'true'
    
    def resolve_variable(self, var_ref: str, context: Dict) -> Any:
        """Resolve a variable reference"""
        if var_ref.startswith('${') and var_ref.endswith('}'):
            var_name = var_ref[2:-1]
            return context['variables'].get(var_name)
        return var_ref
    
    def resolve_variables(self, data: Any, context: Dict) -> Any:
        """Recursively resolve variables in data"""
        if isinstance(data, str):
            return self.resolve_variable(data, context)
        elif isinstance(data, dict):
            return {k: self.resolve_variables(v, context) for k, v in data.items()}
        elif isinstance(data, list):
            return [self.resolve_variables(item, context) for item in data]
        return data
    
    def build_location_query(self, params: Dict) -> str:
        """Build location query SQL"""
        location_type = params.get('type', '')
        has_rack = params.get('has_rack', None)
        
        query = f"SELECT * FROM locations WHERE type = '{location_type}'"
        
        if has_rack is not None:
            query += f" AND has_rack = {has_rack}"
        
        return query
    
    def build_rack_query(self, params: Dict) -> str:
        """Build rack query SQL"""
        location_id = params.get('location_id', '')
        
        return f"SELECT * FROM racks WHERE location_id = '{location_id}'"
    
    def check_rack_status(self, params: Dict, context: Dict) -> bool:
        """Check rack status conditions"""
        # Implementation would query actual rack status
        return True  # Simplified
    
    def check_task_exists(self, params: Dict, context: Dict) -> bool:
        """Check if task already exists"""
        # Implementation would query task database
        return False  # Simplified
    
    def create_agv_task(self, params: Dict, context: Dict) -> str:
        """Create an AGV task"""
        # Implementation would create actual task
        task_id = f"TASK_{datetime.now().strftime('%Y%m%d%H%M%S')}"
        
        self.get_logger().info(f"Created task: {task_id} with params: {params}")
        
        return task_id
    
    def execute_database_query(self, query: str) -> Any:
        """Execute database query via db_proxy"""
        # For now, return mock data
        return []
    
    def publish_flow_status(self, flow_id: str, status: str, error: str = None):
        """Publish flow execution status"""
        status_msg = {
            'flow_id': flow_id,
            'status': status,
            'timestamp': datetime.now().isoformat()
        }
        
        if error:
            status_msg['error'] = error
        
        msg = String()
        msg.data = json.dumps(status_msg)
        self.flow_status_pub.publish(msg)
    
    def handle_flow_trigger(self, msg: String):
        """Handle manual flow trigger"""
        try:
            trigger_data = json.loads(msg.data)
            flow_id = trigger_data.get('flow_id')
            
            if flow_id in self.loaded_flows:
                self.execute_flow(flow_id, self.loaded_flows[flow_id])
                self.get_logger().info(f"Manually triggered flow: {flow_id}")
            else:
                self.get_logger().warning(f"Flow not found: {flow_id}")
        
        except Exception as e:
            self.get_logger().error(f"Failed to handle trigger: {e}")


def main(args=None):
    rclpy.init(args=args)
    node = FlowWCSNode()
    
    try:
        rclpy.spin(node)
    except KeyboardInterrupt:
        pass
    finally:
        node.destroy_node()
        rclpy.shutdown()


if __name__ == '__main__':
    main()