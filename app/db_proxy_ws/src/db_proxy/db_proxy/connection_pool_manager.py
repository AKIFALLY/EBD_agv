import time
import threading
import rclpy.logging
from sqlalchemy import create_engine
from sqlalchemy.pool import QueuePool
from sqlmodel import SQLModel, Session, select, text
import json
from contextlib import contextmanager

# å¸¸æ•¸å®šç¾©
POOL_SIZE = 5
MAX_POOL_SIZE = 10
POOL_TIMEOUT = 30
POOL_RECYCLE = 180
LOG_INTERVAL = 5


class ConnectionPoolManager:
    def __init__(self, db_url, pool_size=POOL_SIZE, max_overflow=MAX_POOL_SIZE-POOL_SIZE, pool_timeout=POOL_TIMEOUT, pool_recycle=POOL_RECYCLE):
        self.logger = rclpy.logging.get_logger('db_connection_pool')
        self.engine = create_engine(
            db_url,
            poolclass=QueuePool,
            pool_size=pool_size,
            max_overflow=max_overflow,
            pool_timeout=pool_timeout,
            pool_recycle=pool_recycle,
            json_serializer=lambda obj: json.dumps(obj, ensure_ascii=False)
        )
        # self.SessionLocal = sessionmaker(...)  # âŒ ä¸è¦å†ç”¨é€™å€‹äº†
        
        # è¨­å®šæ™‚å€ - åªåœ¨åˆå§‹åŒ–æ™‚åŸ·è¡Œä¸€æ¬¡
        if 'postgresql' in str(self.engine.url):
            try:
                with Session(self.engine) as session:
                    # ä½¿ç”¨ SQLModel çš„ exec æ–¹æ³•ä¾†åŸ·è¡Œ SQL
                    session.exec(text("SET TIME ZONE 'Asia/Taipei'"))
                    session.commit()
                    self.logger.info("âœ… æ™‚å€è¨­å®šç‚º Asia/Taipei")
            except Exception as e:
                self.logger.warning(f"âš ï¸ åˆå§‹åŒ–æ™‚å€è¨­å®šå¤±æ•—: {e}")
        
        self.create_tables()
        self.monitoring = True
        self.monitor_thread = threading.Thread(
            target=self.monitor_pool, daemon=True)
        self.monitor_thread.start()

    def create_tables(self):
        self.logger.info("ğŸ”„ å˜—è©¦å»ºç«‹è³‡æ–™è¡¨...")
        SQLModel.metadata.create_all(self.engine)
        self.logger.info("âœ… è³‡æ–™è¡¨å·²å»ºç«‹")

    def monitor_pool(self):
        while self.monitoring:
            self.log_pool_status()
            time.sleep(LOG_INTERVAL)

    def log_pool_status(self):
        pool = self.engine.pool
        self.logger.info(
            f"ğŸ“Š ç¸½é€£ç·šæ•¸: {pool.size()} âœ… å¯ç”¨é€£ç·šæ•¸: {pool.checkedin()} â³ ä½¿ç”¨ä¸­é€£ç·šæ•¸: {pool.checkedout()} ğŸ”„ æ’éšŠä¸­è«‹æ±‚æ•¸: {max(0, pool.overflow())}")

    def get_session(self) -> Session:
        """
        å–å¾—æ¨™æº– sessionï¼Œé©ç”¨æ–¼å¯èƒ½æœ‰å¯«å…¥çš„æ“ä½œã€‚
        æ³¨æ„ï¼šåªè®€æŸ¥è©¢çµæŸæ™‚æœƒè‡ªå‹• rollbackï¼Œé€™æ˜¯æ­£å¸¸çš„ï¼
        PostgreSQL çš„ rollback å°åªè®€äº‹å‹™å¹¾ä¹æ²’æœ‰æˆæœ¬ã€‚
        """
        session = Session(self.engine)
        return session
    
    @contextmanager
    def get_autocommit_session(self):
        """
        å–å¾— autocommit sessionï¼Œé©ç”¨æ–¼ç´”ç²¹çš„åªè®€æŸ¥è©¢ã€‚
        é€™æœƒå®Œå…¨é¿å…äº‹å‹™ï¼Œå› æ­¤ä¸æœƒæœ‰ rollbackã€‚
        è­¦å‘Šï¼šä¸é©åˆéœ€è¦äº‹å‹™ä¸€è‡´æ€§çš„å¤šèªå¥æŸ¥è©¢ï¼
        """
        # å‰µå»ºä¸€å€‹ autocommit é€£æ¥
        conn = self.engine.connect()
        conn.execution_options(isolation_level="AUTOCOMMIT")
        session = Session(bind=conn)
        try:
            yield session
        finally:
            session.close()
            conn.close()

    def shutdown(self):
        self.monitoring = False
        self.engine.dispose()
        self.logger.info("ğŸ”» é€£ç·šæ± å·²é—œé–‰")
