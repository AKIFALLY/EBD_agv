#!/usr/bin/env python3
"""
ç”Ÿæˆ docs-ai æ–‡æª”ç´¢å¼•å’Œå¼•ç”¨çµ±è¨ˆ
æƒææ‰€æœ‰ CLAUDE.md æ–‡ä»¶ä¸­çš„ @docs-ai å¼•ç”¨
è¼¸å‡º JSON ç´¢å¼•ä¾›å‰ç«¯ä½¿ç”¨
"""

import json
import os
import re
from pathlib import Path
from collections import defaultdict
from datetime import datetime

# åŸºç¤è·¯å¾‘é…ç½®
ROSAGV_ROOT = Path("/home/ct/RosAGV")
DOCS_AI_PATH = ROSAGV_ROOT / "docs-ai"
OUTPUT_PATH = ROSAGV_ROOT / "design/business-process-docs/js/docs-ai-index.json"

# æ–‡æª”åˆ†é¡å®šç¾©
CATEGORIES = {
    "core": {
        "name": "ğŸ”¥ æ ¸å¿ƒåŸå‰‡",
        "description": "AI Agent å¿…è®€æ–‡æª”",
        "patterns": [
            "operations/development/core/",
            "operations/tools/unified-tools.md"
        ]
    },
    "architecture": {
        "name": "ğŸ“š ç³»çµ±æ¶æ§‹",
        "description": "ç³»çµ±è¨­è¨ˆå’Œæ¶æ§‹",
        "patterns": [
            "context/system/",
            "context/workspaces/"
        ]
    },
    "operations": {
        "name": "ğŸ“– æ“ä½œæŒ‡å—",
        "description": "é–‹ç™¼å’Œé‹ç¶­æŒ‡å°",
        "patterns": [
            "operations/guides/",
            "operations/deployment/",
            "operations/development/"
        ]
    },
    "knowledge": {
        "name": "ğŸ·ï¸ é ˜åŸŸçŸ¥è­˜",
        "description": "æ¥­å‹™å’ŒæŠ€è¡“çŸ¥è­˜",
        "patterns": [
            "knowledge/"
        ]
    },
    "testing": {
        "name": "ğŸ§ª æ¸¬è©¦æ¨™æº–",
        "description": "æ¸¬è©¦ç›¸é—œæ–‡æª”",
        "patterns": [
            "operations/development/testing/"
        ]
    }
}

def scan_docs_ai_files():
    """æƒææ‰€æœ‰ docs-ai ç›®éŒ„ä¸‹çš„ .md æ–‡ä»¶"""
    docs = {}

    for md_file in DOCS_AI_PATH.rglob("*.md"):
        relative_path = md_file.relative_to(DOCS_AI_PATH)
        path_str = str(relative_path).replace('\\', '/')

        # è®€å–æ–‡ä»¶æ¨™é¡Œå’Œæè¿°
        title = path_str
        description = ""

        try:
            with open(md_file, 'r', encoding='utf-8') as f:
                lines = f.readlines()
                for line in lines[:10]:  # åªæª¢æŸ¥å‰10è¡Œ
                    if line.startswith("# "):
                        title = line[2:].strip()
                    elif line.startswith("## ğŸ¯ é©ç”¨å ´æ™¯"):
                        # è®€å–ä¸‹ä¸€è¡Œä½œç‚ºæè¿°
                        idx = lines.index(line)
                        if idx + 1 < len(lines):
                            description = lines[idx + 1].strip().lstrip("- ")
                        break
        except:
            pass

        # åˆ¤æ–·åˆ†é¡
        category = "other"
        for cat_key, cat_info in CATEGORIES.items():
            for pattern in cat_info["patterns"]:
                if pattern in path_str:
                    category = cat_key
                    break
            if category != "other":
                break

        docs[path_str] = {
            "path": path_str,
            "title": title,
            "description": description[:100] if description else "",
            "category": category,
            "references": 0,  # å°‡ç”±æƒæ CLAUDE.md æ›´æ–°
            "referenced_by": [],
            "size": md_file.stat().st_size,
            "modified": md_file.stat().st_mtime
        }

    return docs

def scan_claude_references():
    """æƒææ‰€æœ‰ CLAUDE.md æ–‡ä»¶ä¸­çš„ @docs-ai å¼•ç”¨"""
    references = defaultdict(list)

    # æƒææ ¹ç›®éŒ„çš„ CLAUDE.md
    claude_files = list(ROSAGV_ROOT.glob("CLAUDE.md"))
    # æƒææ‰€æœ‰å·¥ä½œç©ºé–“çš„ CLAUDE.md
    claude_files.extend(ROSAGV_ROOT.glob("app/**/CLAUDE.md"))

    for claude_file in claude_files:
        relative_claude = claude_file.relative_to(ROSAGV_ROOT)

        try:
            with open(claude_file, 'r', encoding='utf-8') as f:
                content = f.read()

                # æŸ¥æ‰¾æ‰€æœ‰ @docs-ai/ å¼•ç”¨
                pattern = r'@docs-ai/([^\s\]]+\.md)'
                matches = re.findall(pattern, content)

                for match in matches:
                    references[match].append(str(relative_claude))
        except:
            continue

    return references

def categorize_importance(ref_count):
    """æ ¹æ“šå¼•ç”¨æ¬¡æ•¸åˆ¤æ–·é‡è¦æ€§"""
    if ref_count >= 10:
        return "critical"
    elif ref_count >= 5:
        return "important"
    elif ref_count >= 2:
        return "common"
    elif ref_count >= 1:
        return "referenced"
    else:
        return "unreferenced"

def generate_index():
    """ç”Ÿæˆå®Œæ•´çš„ç´¢å¼•æ–‡ä»¶"""
    print("ğŸ” æƒæ docs-ai æ–‡ä»¶...")
    docs = scan_docs_ai_files()

    print("ğŸ“Š æƒæ CLAUDE.md å¼•ç”¨...")
    references = scan_claude_references()

    # æ›´æ–°å¼•ç”¨è¨ˆæ•¸
    for doc_path, ref_list in references.items():
        if doc_path in docs:
            docs[doc_path]["references"] = len(ref_list)
            docs[doc_path]["referenced_by"] = ref_list
            docs[doc_path]["importance"] = categorize_importance(len(ref_list))

    # ç‚ºæœªè¢«å¼•ç”¨çš„æ–‡æª”è¨­ç½®é‡è¦æ€§
    for doc_path, doc_info in docs.items():
        if "importance" not in doc_info:
            doc_info["importance"] = "unreferenced"

    # çµ±è¨ˆä¿¡æ¯
    stats = {
        "total_docs": len(docs),
        "total_references": sum(len(refs) for refs in references.values()),
        "critical_docs": len([d for d in docs.values() if d["importance"] == "critical"]),
        "important_docs": len([d for d in docs.values() if d["importance"] == "important"]),
        "unreferenced_docs": len([d for d in docs.values() if d["importance"] == "unreferenced"]),
        "categories": {
            cat_key: {
                "name": cat_info["name"],
                "description": cat_info["description"],
                "count": len([d for d in docs.values() if d["category"] == cat_key])
            }
            for cat_key, cat_info in CATEGORIES.items()
        },
        "generated_at": datetime.now().isoformat(),
        "generated_by": "generate-docs-ai-index.py"
    }

    # æ§‹å»ºæœ€çµ‚è¼¸å‡º
    output = {
        "stats": stats,
        "categories": CATEGORIES,
        "documents": docs,
        "top_referenced": sorted(
            [d for d in docs.values() if d["references"] > 0],
            key=lambda x: x["references"],
            reverse=True
        )[:10]
    }

    return output

def main():
    """ä¸»å‡½æ•¸"""
    print("=" * 60)
    print("ğŸ“š RosAGV docs-ai ç´¢å¼•ç”Ÿæˆå™¨")
    print("=" * 60)

    # ç”Ÿæˆç´¢å¼•
    index = generate_index()

    # ç¢ºä¿è¼¸å‡ºç›®éŒ„å­˜åœ¨
    OUTPUT_PATH.parent.mkdir(parents=True, exist_ok=True)

    # å¯«å…¥ JSON æ–‡ä»¶
    with open(OUTPUT_PATH, 'w', encoding='utf-8') as f:
        json.dump(index, f, ensure_ascii=False, indent=2)

    print(f"\nâœ… ç´¢å¼•ç”ŸæˆæˆåŠŸï¼")
    print(f"ğŸ“ è¼¸å‡ºæª”æ¡ˆ: {OUTPUT_PATH}")
    print(f"\nğŸ“Š çµ±è¨ˆä¿¡æ¯:")
    print(f"  - ç¸½æ–‡æª”æ•¸: {index['stats']['total_docs']}")
    print(f"  - ç¸½å¼•ç”¨æ•¸: {index['stats']['total_references']}")
    print(f"  - é—œéµæ–‡æª”: {index['stats']['critical_docs']}")
    print(f"  - é‡è¦æ–‡æª”: {index['stats']['important_docs']}")
    print(f"  - æœªå¼•ç”¨æ–‡æª”: {index['stats']['unreferenced_docs']}")

    print(f"\nğŸ”¥ æœ€å¸¸è¢«å¼•ç”¨çš„æ–‡æª”:")
    for i, doc in enumerate(index["top_referenced"][:5], 1):
        print(f"  {i}. {doc['title']} ({doc['references']} æ¬¡)")
        print(f"     è·¯å¾‘: {doc['path']}")

if __name__ == "__main__":
    main()