# æ•ˆèƒ½èª¿å„ª

## ğŸ¯ RosAGV ç³»çµ±æ•ˆèƒ½æœ€ä½³åŒ–æŒ‡å—

æœ¬æ–‡æª”æä¾› RosAGV ç³»çµ±çš„å®Œæ•´æ•ˆèƒ½èª¿å„ªç­–ç•¥ï¼ŒåŒ…æ‹¬ç³»çµ±å±¤ç´šæœ€ä½³åŒ–ã€æ‡‰ç”¨ç¨‹å¼èª¿å„ªã€è³‡æ–™åº«æœ€ä½³åŒ–å’Œç¶²è·¯æ•ˆèƒ½æå‡ã€‚

## ğŸ“Š æ•ˆèƒ½èª¿å„ªæ¦‚è¦½

### æœ€ä½³åŒ–å±¤æ¬¡
```
æ•ˆèƒ½æœ€ä½³åŒ–æ¶æ§‹
â”œâ”€â”€ ğŸ–¥ï¸ ç³»çµ±å±¤ç´šæœ€ä½³åŒ–
â”‚   â”œâ”€â”€ ä½œæ¥­ç³»çµ±èª¿å„ª
â”‚   â”œâ”€â”€ ç¡¬é«”è³‡æºæœ€ä½³åŒ–
â”‚   â””â”€â”€ æ ¸å¿ƒåƒæ•¸èª¿æ•´
â”œâ”€â”€ ğŸ³ å®¹å™¨å±¤ç´šæœ€ä½³åŒ–
â”‚   â”œâ”€â”€ Docker è¨­å®šèª¿å„ª
â”‚   â”œâ”€â”€ è³‡æºé™åˆ¶æœ€ä½³åŒ–
â”‚   â””â”€â”€ æ˜ åƒæœ€ä½³åŒ–
â”œâ”€â”€ ğŸš€ æ‡‰ç”¨ç¨‹å¼æœ€ä½³åŒ–
â”‚   â”œâ”€â”€ ROS 2 æ•ˆèƒ½èª¿å„ª
â”‚   â”œâ”€â”€ Python æ‡‰ç”¨æœ€ä½³åŒ–
â”‚   â””â”€â”€ Web æœå‹™èª¿å„ª
â””â”€â”€ ğŸŒ ç¶²è·¯å’Œè³‡æ–™æœ€ä½³åŒ–
    â”œâ”€â”€ ç¶²è·¯é€šè¨Šæœ€ä½³åŒ–
    â”œâ”€â”€ è³‡æ–™åº«æ•ˆèƒ½èª¿å„ª
    â””â”€â”€ å¿«å–ç­–ç•¥å¯¦æ–½
```

## ğŸ–¥ï¸ ç³»çµ±å±¤ç´šæœ€ä½³åŒ–

### ä½œæ¥­ç³»çµ±èª¿å„ª
```bash
# Linux æ ¸å¿ƒåƒæ•¸èª¿å„ª
# /etc/sysctl.conf
# ç¶²è·¯æ•ˆèƒ½æœ€ä½³åŒ–
net.core.rmem_max = 67108864
net.core.wmem_max = 67108864
net.ipv4.tcp_rmem = 4096 87380 67108864
net.ipv4.tcp_wmem = 4096 65536 67108864

# è¨˜æ†¶é«”ç®¡ç†æœ€ä½³åŒ–
vm.swappiness = 10
vm.vfs_cache_pressure = 50
vm.dirty_ratio = 15
vm.dirty_background_ratio = 5

# æª”æ¡ˆæè¿°ç¬¦é™åˆ¶
fs.file-max = 100000
net.core.somaxconn = 1024

# å¥—ç”¨è¨­å®š
sudo sysctl -p
```

### CPU æ•ˆèƒ½æœ€ä½³åŒ–
```bash
# CPU èª¿åº¦å™¨æœ€ä½³åŒ–
echo performance | sudo tee /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor

# CPU è¦ªå’Œæ€§è¨­å®š
#!/bin/bash
# set-cpu-affinity.sh
# ç‚ºé—œéµé€²ç¨‹è¨­å®š CPU è¦ªå’Œæ€§
AGVC_PID=$(pgrep -f "agvc_server")
POSTGRES_PID=$(pgrep -f "postgres")

# AGVC æœå‹™ä½¿ç”¨ CPU 0-3
taskset -cp 0-3 $AGVC_PID

# PostgreSQL ä½¿ç”¨ CPU 4-7
taskset -cp 4-7 $POSTGRES_PID
```

### è¨˜æ†¶é«”æœ€ä½³åŒ–
```bash
# è¨˜æ†¶é«”åˆ†é…æœ€ä½³åŒ–
# è¨­å®šé€æ˜å¤§é é¢
echo madvise | sudo tee /sys/kernel/mm/transparent_hugepage/enabled

# NUMA æœ€ä½³åŒ– (å¤š CPU ç³»çµ±)
echo 0 | sudo tee /proc/sys/kernel/numa_balancing
```

## ğŸ³ å®¹å™¨å±¤ç´šæœ€ä½³åŒ–

### Docker è¨­å®šèª¿å„ª
```yaml
# docker-compose.agvc.yml - æ•ˆèƒ½æœ€ä½³åŒ–ç‰ˆæœ¬
version: '3.8'
services:
  agvc_server:
    deploy:
      resources:
        reservations:
          memory: 2G
          cpus: '2.0'
        limits:
          memory: 4G
          cpus: '4.0'
    # ä½¿ç”¨ host ç¶²è·¯æ¨¡å¼æå‡ç¶²è·¯æ•ˆèƒ½ (ç”Ÿç”¢ç’°å¢ƒ)
    # network_mode: host
    
    # å„ªåŒ–å®¹å™¨è¨­å®š
    tmpfs:
      - /tmp:size=1G,noexec,nosuid,nodev
    shm_size: 2g
    
    # CPU è¨­å®š
    cpuset: "0-3"
    cpu_shares: 1024
    
    # è¨˜æ†¶é«”è¨­å®š
    mem_swappiness: 0
    oom_kill_disable: false

  postgres:
    deploy:
      resources:
        reservations:
          memory: 1G
          cpus: '1.0'
        limits:
          memory: 2G
          cpus: '2.0'
    
    # PostgreSQL ç‰¹å®šæœ€ä½³åŒ–
    command: >
      postgres
      -c shared_buffers=256MB
      -c effective_cache_size=1GB
      -c maintenance_work_mem=64MB
      -c checkpoint_completion_target=0.7
      -c wal_buffers=16MB
      -c default_statistics_target=100
```

### æ˜ åƒæœ€ä½³åŒ–
```dockerfile
# Dockerfile æœ€ä½³åŒ–ç¯„ä¾‹
FROM ubuntu:24.04 as base

# ä½¿ç”¨å¤šéšæ®µå»ºç½®æ¸›å°‘æ˜ åƒå¤§å°
FROM base as builder
RUN apt-get update && apt-get install -y build-essential
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

FROM base as runtime
# åªè¤‡è£½å¿…è¦æª”æ¡ˆ
COPY --from=builder /usr/local/lib/python3.12/site-packages /usr/local/lib/python3.12/site-packages
COPY app/ /app/

# æœ€ä½³åŒ–è¨­å®š
ENV PYTHONUNBUFFERED=1
ENV PYTHONDONTWRITEBYTECODE=1
```

## ğŸš€ æ‡‰ç”¨ç¨‹å¼æœ€ä½³åŒ–

### ROS 2 æ•ˆèƒ½èª¿å„ª
```bash
# ROS 2 ç’°å¢ƒè®Šæ•¸æœ€ä½³åŒ–
export RMW_IMPLEMENTATION=rmw_zenohd
export ROS_LOCALHOST_ONLY=0
export ROS_DISABLE_LOANED_MESSAGES=0

# DDS æœ€ä½³åŒ–è¨­å®š
export FASTRTPS_DEFAULT_PROFILES_FILE=/app/config/fastrtps_profile.xml
```

```xml
<!-- fastrtps_profile.xml - FastDDS æ•ˆèƒ½æœ€ä½³åŒ– -->
<?xml version="1.0" encoding="UTF-8"?>
<profiles>
    <transport_descriptors>
        <transport_descriptor>
            <transport_id>udp_transport</transport_id>
            <type>UDPv4</type>
            <sendBufferSize>262144</sendBufferSize>
            <receiveBufferSize>262144</receiveBufferSize>
        </transport_descriptor>
    </transport_descriptors>
    
    <participant profile_name="high_performance_participant">
        <rtps>
            <userTransports>
                <transport_id>udp_transport</transport_id>
            </userTransports>
            <use_builtin_transports>false</use_builtin_transports>
        </rtps>
    </participant>
</profiles>
```

### Python æ‡‰ç”¨æœ€ä½³åŒ–
```python
# Python æ•ˆèƒ½æœ€ä½³åŒ–æŠ€å·§
import asyncio
import uvloop
from functools import lru_cache
import multiprocessing

# 1. ä½¿ç”¨ uvloop æå‡ç•°æ­¥æ•ˆèƒ½
asyncio.set_event_loop_policy(uvloop.EventLoopPolicy())

# 2. å¿«å–é »ç¹ä½¿ç”¨çš„å‡½æ•¸
@lru_cache(maxsize=128)
def expensive_computation(param):
    # æ˜‚è²´çš„è¨ˆç®—æ“ä½œ
    return result

# 3. ä½¿ç”¨å¤šé€²ç¨‹è™•ç† CPU å¯†é›†ä»»å‹™
class PerformanceOptimizer:
    def __init__(self):
        self.process_pool = multiprocessing.Pool(
            processes=multiprocessing.cpu_count())
    
    async def process_heavy_task(self, data):
        """ç•°æ­¥è™•ç† CPU å¯†é›†ä»»å‹™"""
        loop = asyncio.get_event_loop()
        result = await loop.run_in_executor(
            self.process_pool, self.cpu_intensive_task, data)
        return result
```

### Web æœå‹™èª¿å„ª
```python
# FastAPI æ•ˆèƒ½æœ€ä½³åŒ–
from fastapi import FastAPI
from fastapi.middleware.gzip import GZipMiddleware
from fastapi.middleware.trustedhost import TrustedHostMiddleware
import uvicorn

app = FastAPI()

# 1. å•Ÿç”¨ GZIP å£“ç¸®
app.add_middleware(GZipMiddleware, minimum_size=1000)

# 2. ä¿¡ä»»ä¸»æ©Ÿä¸­é–“ä»¶
app.add_middleware(
    TrustedHostMiddleware, allowed_hosts=["localhost", "*.company.com"])

# 3. æœ€ä½³åŒ– Uvicorn è¨­å®š
if __name__ == "__main__":
    uvicorn.run(
        "main:app",
        host="0.0.0.0",
        port=8000,
        workers=4,  # å¤šå·¥ä½œé€²ç¨‹
        loop="uvloop",  # ä½¿ç”¨ uvloop
        http="h11",  # HTTP è§£æå™¨
        access_log=False,  # é—œé–‰å­˜å–æ—¥èªŒæå‡æ•ˆèƒ½
        log_level="warning"
    )
```

## ğŸ—„ï¸ è³‡æ–™åº«æ•ˆèƒ½èª¿å„ª

### PostgreSQL è¨­å®šæœ€ä½³åŒ–
```sql
-- postgresql.conf æœ€ä½³åŒ–è¨­å®š
-- è¨˜æ†¶é«”è¨­å®š
shared_buffers = 256MB                    -- 25% of RAM
effective_cache_size = 1GB                -- 75% of RAM
work_mem = 32MB                           -- æ ¹æ“šä¸¦ç™¼æŸ¥è©¢èª¿æ•´
maintenance_work_mem = 64MB               -- ç¶­è­·æ“ä½œè¨˜æ†¶é«”

-- æª¢æŸ¥é»è¨­å®š
checkpoint_completion_target = 0.7        -- æª¢æŸ¥é»å®Œæˆç›®æ¨™
wal_buffers = 16MB                        -- WAL ç·©è¡å€
checkpoint_timeout = 10min                -- æª¢æŸ¥é»è¶…æ™‚

-- æŸ¥è©¢æœ€ä½³åŒ–
default_statistics_target = 100           -- çµ±è¨ˆç›®æ¨™
random_page_cost = 1.1                    -- SSD ç¡¬ç¢Ÿè¨­å®š
effective_io_concurrency = 200            -- SSD ä¸¦ç™¼ I/O

-- é€£æ¥è¨­å®š
max_connections = 200                     -- æœ€å¤§é€£æ¥æ•¸
shared_preload_libraries = 'pg_stat_statements'  -- è¼‰å…¥çµ±è¨ˆæ“´å±•
```

### ç´¢å¼•æœ€ä½³åŒ–
```sql
-- åˆ†ææŸ¥è©¢æ•ˆèƒ½
CREATE EXTENSION IF NOT EXISTS pg_stat_statements;

-- æŸ¥æ‰¾æ…¢æŸ¥è©¢
SELECT 
    query,
    mean_time,
    calls,
    total_time,
    rows,
    100.0 * shared_blks_hit / nullif(shared_blks_hit + shared_blks_read, 0) AS hit_percent
FROM pg_stat_statements 
ORDER BY mean_time DESC 
LIMIT 10;

-- å‰µå»ºè¤‡åˆç´¢å¼•æœ€ä½³åŒ–æŸ¥è©¢
CREATE INDEX CONCURRENTLY idx_agv_status_timestamp 
ON agv_status (agv_id, created_at DESC);

-- å®šæœŸé‡å»ºç´¢å¼•
REINDEX INDEX CONCURRENTLY idx_agv_status_timestamp;
```

### é€£æ¥æ± æœ€ä½³åŒ–
```python
# SQLAlchemy é€£æ¥æ± æœ€ä½³åŒ–
from sqlalchemy import create_engine
from sqlalchemy.pool import QueuePool

engine = create_engine(
    DATABASE_URL,
    poolclass=QueuePool,
    pool_size=10,              # é€£æ¥æ± å¤§å°
    max_overflow=20,           # æœ€å¤§æº¢å‡ºé€£æ¥
    pool_pre_ping=True,        # é€£æ¥å‰æ¸¬è©¦
    pool_recycle=300,          # é€£æ¥å›æ”¶æ™‚é–“ (ç§’)
    echo=False                 # é—œé–‰ SQL æ—¥èªŒæå‡æ•ˆèƒ½
)
```

## ğŸŒ ç¶²è·¯å’Œé€šè¨Šæœ€ä½³åŒ–

### Zenoh é€šè¨Šæœ€ä½³åŒ–
```json5
// routerconfig.json5 - æ•ˆèƒ½æœ€ä½³åŒ–ç‰ˆæœ¬
{
  "mode": "router",
  
  // é«˜æ•ˆèƒ½å‚³è¼¸è¨­å®š
  "transport": {
    "unicast": {
      "lowlatency": true,        // å•Ÿç”¨ä½å»¶é²æ¨¡å¼
      "qos": {
        "enabled": true,
        "unicast": {
          "reliability": "reliable",
          "congestion_control": "block"
        }
      },
      "compression": {
        "enabled": false         // é—œé–‰å£“ç¸®æ¸›å°‘ CPU ä½¿ç”¨
      }
    }
  },
  
  // æœ€ä½³åŒ–è·¯ç”±è¨­å®š
  "routing": {
    "face": {
      "unicast": {
        "accept_timeout": 5000,
        "max_sessions": 2000,    // å¢åŠ æœ€å¤§æœƒè©±æ•¸
        "max_links": 4           // å¢åŠ é€£çµæ•¸
      }
    }
  },
  
  // è¨˜æ†¶é«”æœ€ä½³åŒ–
  "plugins": {
    "zenoh-plugin-dds": {
      "shm": {
        "enabled": true,
        "size": "1GB"           // å¢åŠ å…±äº«è¨˜æ†¶é«”å¤§å°
      }
    }
  }
}
```

### HTTP æœå‹™æœ€ä½³åŒ–
```nginx
# nginx.conf æ•ˆèƒ½æœ€ä½³åŒ–
worker_processes auto;
worker_rlimit_nofile 100000;

events {
    worker_connections 4000;
    use epoll;
    multi_accept on;
}

http {
    # å¿«å–è¨­å®š
    open_file_cache max=200000 inactive=20s;
    open_file_cache_valid 30s;
    open_file_cache_min_uses 2;
    open_file_cache_errors on;
    
    # GZIP å£“ç¸®
    gzip on;
    gzip_min_length 10240;
    gzip_comp_level 1;
    gzip_vary on;
    gzip_types text/plain text/css application/json application/javascript;
    
    # Keep-alive è¨­å®š
    keepalive_timeout 30;
    keepalive_requests 100;
    
    # ç·©è¡å€è¨­å®š
    client_body_buffer_size 128k;
    client_max_body_size 10m;
    client_header_buffer_size 1k;
    large_client_header_buffers 4 4k;
    
    upstream agvc_backend {
        server 127.0.0.1:8000;
        keepalive 32;
    }
}
```

## ğŸ“Š æ•ˆèƒ½ç›£æ§å’ŒåŸºæº–æ¸¬è©¦

### æ•ˆèƒ½åŸºæº–æ¸¬è©¦
```bash
#!/bin/bash
# performance-benchmark.sh
echo "=== RosAGV æ•ˆèƒ½åŸºæº–æ¸¬è©¦ ==="

# 1. API æ•ˆèƒ½æ¸¬è©¦
echo "1. API æ•ˆèƒ½æ¸¬è©¦"
ab -n 1000 -c 10 http://localhost:8000/health
wrk -t4 -c100 -d30s http://localhost:8000/health

# 2. è³‡æ–™åº«æ•ˆèƒ½æ¸¬è©¦
echo "2. è³‡æ–™åº«æ•ˆèƒ½æ¸¬è©¦"
docker compose -f docker-compose.agvc.yml exec postgres pgbench -i agvc
docker compose -f docker-compose.agvc.yml exec postgres pgbench -c 10 -j 2 -T 60 agvc

# 3. ROS 2 é€šè¨Šæ•ˆèƒ½æ¸¬è©¦
echo "3. ROS 2 é€šè¨Šæ•ˆèƒ½æ¸¬è©¦"
ros2 topic hz /agv_status --window 100
ros2 topic bw /agv_status

# 4. ç³»çµ±è² è¼‰æ¸¬è©¦
echo "4. ç³»çµ±è² è¼‰æ¸¬è©¦"
stress --cpu 4 --io 2 --vm 2 --timeout 60s
```

### æ•ˆèƒ½ç›£æ§æŒ‡æ¨™
```python
class PerformanceMetrics:
    def __init__(self):
        self.metrics = {
            'api_response_time': [],
            'database_query_time': [],
            'ros2_message_latency': [],
            'system_resource_usage': {},
            'network_throughput': []
        }
    
    def collect_metrics(self):
        """æ”¶é›†æ•ˆèƒ½æŒ‡æ¨™"""
        # API éŸ¿æ‡‰æ™‚é–“
        api_latency = self.measure_api_latency()
        self.metrics['api_response_time'].append(api_latency)
        
        # è³‡æ–™åº«æŸ¥è©¢æ™‚é–“
        db_latency = self.measure_database_latency()
        self.metrics['database_query_time'].append(db_latency)
        
        # ROS 2 è¨Šæ¯å»¶é²
        ros2_latency = self.measure_ros2_latency()
        self.metrics['ros2_message_latency'].append(ros2_latency)
        
        return self.generate_performance_report()
```

## ğŸ¯ æ•ˆèƒ½èª¿å„ªæª¢æŸ¥æ¸…å–®

### ç³»çµ±å±¤ç´š
- [ ] æ ¸å¿ƒåƒæ•¸å·²æœ€ä½³åŒ–
- [ ] CPU èª¿åº¦å™¨è¨­ç‚º performance æ¨¡å¼
- [ ] è¨˜æ†¶é«”äº¤æ›è¨­å®šå·²èª¿æ•´
- [ ] æª”æ¡ˆæè¿°ç¬¦é™åˆ¶å·²æé«˜

### å®¹å™¨å±¤ç´š
- [ ] è³‡æºé™åˆ¶å·²åˆç†è¨­å®š
- [ ] CPU è¦ªå’Œæ€§å·²é…ç½®
- [ ] å…±äº«è¨˜æ†¶é«”å·²æœ€ä½³åŒ–
- [ ] æ˜ åƒå¤§å°å·²æœ€å°åŒ–

### æ‡‰ç”¨ç¨‹å¼å±¤ç´š
- [ ] ROS 2 è¨­å®šå·²èª¿å„ª
- [ ] Python æ•ˆèƒ½å·²æœ€ä½³åŒ–
- [ ] Web æœå‹™è¨­å®šå·²èª¿æ•´
- [ ] å¿«å–æ©Ÿåˆ¶å·²å¯¦æ–½

### è³‡æ–™åº«å±¤ç´š
- [ ] PostgreSQL åƒæ•¸å·²èª¿å„ª
- [ ] ç´¢å¼•å·²æœ€ä½³åŒ–
- [ ] é€£æ¥æ± å·²é…ç½®
- [ ] æŸ¥è©¢æ•ˆèƒ½å·²åˆ†æ

---

**ç›¸é—œæ–‡æª”ï¼š**
- [ç³»çµ±è¨ºæ–·](../operations/system-diagnostics.md) - æ•ˆèƒ½å•é¡Œè¨ºæ–·
- [ç¶­è­·æ“ä½œ](../operations/maintenance.md) - æ•ˆèƒ½ç›£æ§æŒ‡å°  
- [é›™ç’°å¢ƒæ¶æ§‹](../system-architecture/dual-environment.md) - æ¶æ§‹æœ€ä½³åŒ–
- [Zenoh é€šè¨Š](zenoh-communication.md) - é€šè¨Šæ•ˆèƒ½èª¿å„ª