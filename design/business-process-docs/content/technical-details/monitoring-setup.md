# ç›£æ§ç³»çµ±é…ç½®

## ğŸ¯ RosAGV ç›£æ§ç³»çµ±è¨­å®šæŒ‡å—

æœ¬æ–‡æª”æä¾› RosAGV ç³»çµ±å®Œæ•´çš„ç›£æ§ç³»çµ±é…ç½®ï¼ŒåŒ…æ‹¬æŒ‡æ¨™æ”¶é›†ã€å‘Šè­¦è¨­å®šã€è¦–è¦ºåŒ–å„€è¡¨æ¿å’Œè‡ªå‹•åŒ–ç›£æ§æµç¨‹ã€‚

## ğŸ“Š ç›£æ§ç³»çµ±æ¶æ§‹

### ç›£æ§æ¶æ§‹æ¦‚è¦½
```
RosAGV ç›£æ§ç³»çµ±æ¶æ§‹
â”œâ”€â”€ ğŸ“Š æŒ‡æ¨™æ”¶é›†å±¤
â”‚   â”œâ”€â”€ ç³»çµ±æŒ‡æ¨™æ”¶é›† (Node Exporter)
â”‚   â”œâ”€â”€ å®¹å™¨æŒ‡æ¨™æ”¶é›† (cAdvisor)
â”‚   â”œâ”€â”€ æ‡‰ç”¨æŒ‡æ¨™æ”¶é›† (Custom Metrics)
â”‚   â””â”€â”€ ROS 2 æŒ‡æ¨™æ”¶é›† (ROS Metrics)
â”œâ”€â”€ ğŸ’¾ æŒ‡æ¨™å„²å­˜å±¤
â”‚   â”œâ”€â”€ Prometheus (æ™‚åºè³‡æ–™åº«)
â”‚   â”œâ”€â”€ InfluxDB (é«˜é »è³‡æ–™)
â”‚   â””â”€â”€ æ—¥èªŒèšåˆ (ELK Stack)
â”œâ”€â”€ ğŸ¨ è¦–è¦ºåŒ–å±¤
â”‚   â”œâ”€â”€ Grafana å„€è¡¨æ¿
â”‚   â”œâ”€â”€ Web ç›£æ§ç•Œé¢
â”‚   â””â”€â”€ è¡Œå‹•ç«¯ç›£æ§
â””â”€â”€ ğŸš¨ å‘Šè­¦é€šçŸ¥å±¤
    â”œâ”€â”€ AlertManager
    â”œâ”€â”€ Email/SMS é€šçŸ¥
    â””â”€â”€ Slack/Teams æ•´åˆ
```

## ğŸ“ˆ Prometheus ç›£æ§è¨­å®š

### Prometheus é…ç½®
```yaml
# prometheus.yml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

rule_files:
  - "rosagv_alerts.yml"

alerting:
  alertmanagers:
    - static_configs:
        - targets:
          - alertmanager:9093

scrape_configs:
  # RosAGV ç³»çµ±ç›£æ§
  - job_name: 'rosagv-system'
    static_configs:
      - targets: ['localhost:9100']  # Node Exporter
    scrape_interval: 5s
    
  # Docker å®¹å™¨ç›£æ§
  - job_name: 'rosagv-containers'
    static_configs:
      - targets: ['localhost:8080']  # cAdvisor
    scrape_interval: 10s
    
  # RosAGV æ‡‰ç”¨ç›£æ§
  - job_name: 'rosagv-app'
    static_configs:
      - targets: ['localhost:8000', 'localhost:8001', 'localhost:8002']
    metrics_path: '/metrics'
    scrape_interval: 15s
    
  # PostgreSQL ç›£æ§
  - job_name: 'postgres'
    static_configs:
      - targets: ['localhost:9187']  # Postgres Exporter
    scrape_interval: 30s
    
  # ROS 2 ç¯€é»ç›£æ§
  - job_name: 'ros2-nodes'
    static_configs:
      - targets: ['localhost:9200']  # ROS 2 Metrics Exporter
    scrape_interval: 10s
```

### RosAGV è‡ªå®šç¾©æŒ‡æ¨™
```python
# RosAGV æ‡‰ç”¨æŒ‡æ¨™æ”¶é›†
from prometheus_client import Counter, Histogram, Gauge, start_http_server
import time

class RosAGVMetrics:
    def __init__(self):
        # è¨ˆæ•¸å™¨æŒ‡æ¨™
        self.task_counter = Counter(
            'rosagv_tasks_total', 
            'Total number of tasks processed',
            ['task_type', 'status']
        )
        
        # ç›´æ–¹åœ–æŒ‡æ¨™ (å»¶é²åˆ†ä½ˆ)
        self.task_duration = Histogram(
            'rosagv_task_duration_seconds',
            'Task processing duration',
            ['task_type']
        )
        
        # å„€è¡¨æŒ‡æ¨™ (ç•¶å‰ç‹€æ…‹)
        self.active_agvs = Gauge(
            'rosagv_active_vehicles',
            'Number of active AGV vehicles',
            ['vehicle_type']
        )
        
        self.system_health = Gauge(
            'rosagv_system_health_score',
            'Overall system health score (0-100)'
        )
        
        # å•Ÿå‹• HTTP æœå‹™å™¨ä¾› Prometheus æŠ“å–
        start_http_server(8090)
    
    def record_task_completion(self, task_type, duration, status):
        """è¨˜éŒ„ä»»å‹™å®Œæˆ"""
        self.task_counter.labels(task_type=task_type, status=status).inc()
        self.task_duration.labels(task_type=task_type).observe(duration)
    
    def update_vehicle_count(self, vehicle_type, count):
        """æ›´æ–°è»Šè¼›æ•¸é‡"""
        self.active_agvs.labels(vehicle_type=vehicle_type).set(count)
    
    def update_health_score(self, score):
        """æ›´æ–°å¥åº·åˆ†æ•¸"""
        self.system_health.set(score)

# åœ¨ FastAPI æ‡‰ç”¨ä¸­æ•´åˆ
from fastapi import FastAPI
app = FastAPI()
metrics = RosAGVMetrics()

@app.get("/metrics")
async def get_metrics():
    """Prometheus æŒ‡æ¨™ç«¯é»"""
    # Prometheus client æœƒè‡ªå‹•è™•ç†
    pass
```

## ğŸ¨ Grafana å„€è¡¨æ¿è¨­å®š

### RosAGV ä¸»å„€è¡¨æ¿
```json
{
  "dashboard": {
    "id": null,
    "title": "RosAGV System Overview",
    "tags": ["rosagv", "monitoring"],
    "timezone": "browser",
    "panels": [
      {
        "id": 1,
        "title": "System Health Score",
        "type": "stat",
        "targets": [
          {
            "expr": "rosagv_system_health_score",
            "legendFormat": "Health Score"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "min": 0,
            "max": 100,
            "unit": "percent",
            "thresholds": {
              "steps": [
                {"color": "red", "value": 0},
                {"color": "yellow", "value": 70},
                {"color": "green", "value": 85}
              ]
            }
          }
        }
      },
      {
        "id": 2,
        "title": "Active AGV Vehicles",
        "type": "graph",
        "targets": [
          {
            "expr": "sum by (vehicle_type) (rosagv_active_vehicles)",
            "legendFormat": "{{vehicle_type}}"
          }
        ]
      },
      {
        "id": 3,
        "title": "Task Processing Rate",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(rosagv_tasks_total[5m])",
            "legendFormat": "Tasks/sec"
          }
        ]
      },
      {
        "id": 4,
        "title": "System Resource Usage",
        "type": "graph",
        "targets": [
          {
            "expr": "100 - (avg(irate(node_cpu_seconds_total{mode=\"idle\"}[5m])) * 100)",
            "legendFormat": "CPU Usage %"
          },
          {
            "expr": "100 * (1 - node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)",
            "legendFormat": "Memory Usage %"
          }
        ]
      }
    ]
  }
}
```

### å®¹å™¨ç›£æ§å„€è¡¨æ¿
```json
{
  "dashboard": {
    "title": "RosAGV Container Monitoring",
    "panels": [
      {
        "title": "Container CPU Usage",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(container_cpu_usage_seconds_total{name=~\"agvc_server|postgres|nginx|rosagv\"}[5m]) * 100",
            "legendFormat": "{{name}}"
          }
        ]
      },
      {
        "title": "Container Memory Usage",
        "type": "graph", 
        "targets": [
          {
            "expr": "container_memory_usage_bytes{name=~\"agvc_server|postgres|nginx|rosagv\"} / 1024 / 1024",
            "legendFormat": "{{name}} MB"
          }
        ]
      },
      {
        "title": "Container Network I/O",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(container_network_receive_bytes_total{name=~\"agvc_server|postgres|nginx|rosagv\"}[5m])",
            "legendFormat": "{{name}} RX"
          },
          {
            "expr": "rate(container_network_transmit_bytes_total{name=~\"agvc_server|postgres|nginx|rosagv\"}[5m])",
            "legendFormat": "{{name}} TX"
          }
        ]
      }
    ]
  }
}
```

## ğŸš¨ å‘Šè­¦è¦å‰‡é…ç½®

### Prometheus å‘Šè­¦è¦å‰‡
```yaml
# rosagv_alerts.yml
groups:
  - name: rosagv.rules
    rules:
      # ç³»çµ±å¥åº·å‘Šè­¦
      - alert: SystemHealthLow
        expr: rosagv_system_health_score < 70
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "RosAGV system health is low"
          description: "System health score is {{ $value }}%"
      
      - alert: SystemHealthCritical
        expr: rosagv_system_health_score < 50
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: "RosAGV system health is critical"
          description: "System health score is {{ $value }}%"
      
      # å®¹å™¨è³‡æºå‘Šè­¦
      - alert: HighCPUUsage
        expr: rate(container_cpu_usage_seconds_total[5m]) * 100 > 80
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "High CPU usage detected"
          description: "Container {{ $labels.name }} CPU usage is {{ $value }}%"
      
      - alert: HighMemoryUsage
        expr: container_memory_usage_bytes / container_spec_memory_limit_bytes * 100 > 85
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High memory usage detected"
          description: "Container {{ $labels.name }} memory usage is {{ $value }}%"
      
      # æ‡‰ç”¨æœå‹™å‘Šè­¦
      - alert: ServiceDown
        expr: up{job="rosagv-app"} == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "RosAGV service is down"
          description: "Service {{ $labels.instance }} is not responding"
      
      # è³‡æ–™åº«å‘Šè­¦
      - alert: DatabaseConnectionsHigh
        expr: pg_stat_database_numbackends > 80
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High database connections"
          description: "PostgreSQL has {{ $value }} active connections"
      
      # ROS 2 ç¯€é»å‘Šè­¦
      - alert: ROS2NodeDown
        expr: ros2_node_status == 0
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: "ROS 2 node is down"
          description: "ROS 2 node {{ $labels.node_name }} is not active"
```

### AlertManager é…ç½®
```yaml
# alertmanager.yml
global:
  smtp_smarthost: 'smtp.company.com:587'
  smtp_from: 'alerts@company.com'
  smtp_auth_username: 'alerts@company.com'
  smtp_auth_password: 'password'

route:
  group_by: ['alertname', 'severity']
  group_wait: 10s
  group_interval: 10s
  repeat_interval: 1h
  receiver: 'web.hook'
  routes:
    - match:
        severity: critical
      receiver: 'critical-alerts'
    - match:
        severity: warning
      receiver: 'warning-alerts'

receivers:
  - name: 'web.hook'
    email_configs:
      - to: 'chieu@ms43.hinet.net'
        subject: 'RosAGV Alert: {{ .GroupLabels.alertname }}'
        body: |
          {{ range .Alerts }}
          Alert: {{ .Annotations.summary }}
          Description: {{ .Annotations.description }}
          {{ end }}

  - name: 'critical-alerts'
    email_configs:
      - to: 'chieu@ms43.hinet.net'
        subject: 'ğŸš¨ CRITICAL: RosAGV {{ .GroupLabels.alertname }}'
    slack_configs:
      - api_url: 'https://hooks.slack.com/services/...'
        channel: '#rosagv-alerts'
        title: 'Critical RosAGV Alert'
        text: '{{ range .Alerts }}{{ .Annotations.summary }}{{ end }}'

  - name: 'warning-alerts'
    email_configs:
      - to: 'team@company.com'
        subject: 'âš ï¸ WARNING: RosAGV {{ .GroupLabels.alertname }}'
```

## ğŸ“± è¡Œå‹•ç«¯ç›£æ§æ‡‰ç”¨

### ç›£æ§ Web æ‡‰ç”¨
```html
<!-- mobile-monitor.html -->
<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>RosAGV Mobile Monitor</title>
    <style>
        body { font-family: Arial, sans-serif; margin: 0; padding: 20px; }
        .metric-card { 
            background: #f5f5f5; 
            padding: 15px; 
            margin: 10px 0; 
            border-radius: 8px; 
        }
        .metric-value { font-size: 24px; font-weight: bold; }
        .metric-label { color: #666; font-size: 14px; }
        .status-ok { color: #28a745; }
        .status-warning { color: #ffc107; }
        .status-critical { color: #dc3545; }
    </style>
</head>
<body>
    <h1>RosAGV System Status</h1>
    
    <div class="metric-card">
        <div class="metric-label">System Health</div>
        <div class="metric-value" id="health-score">--</div>
    </div>
    
    <div class="metric-card">
        <div class="metric-label">Active AGVs</div>
        <div class="metric-value" id="active-agvs">--</div>
    </div>
    
    <div class="metric-card">
        <div class="metric-label">Tasks/Hour</div>
        <div class="metric-value" id="task-rate">--</div>
    </div>
    
    <script>
        async function updateMetrics() {
            try {
                const response = await fetch('/api/metrics/summary');
                const data = await response.json();
                
                document.getElementById('health-score').textContent = 
                    data.health_score + '%';
                document.getElementById('active-agvs').textContent = 
                    data.active_agvs;
                document.getElementById('task-rate').textContent = 
                    data.tasks_per_hour;
                    
                // æ›´æ–°ç‹€æ…‹é¡è‰²
                const healthElement = document.getElementById('health-score');
                if (data.health_score >= 85) {
                    healthElement.className = 'metric-value status-ok';
                } else if (data.health_score >= 70) {
                    healthElement.className = 'metric-value status-warning';
                } else {
                    healthElement.className = 'metric-value status-critical';
                }
            } catch (error) {
                console.error('Failed to update metrics:', error);
            }
        }
        
        // æ¯ 30 ç§’æ›´æ–°ä¸€æ¬¡
        setInterval(updateMetrics, 30000);
        updateMetrics(); // åˆå§‹è¼‰å…¥
    </script>
</body>
</html>
```

## ğŸ”§ è‡ªå‹•åŒ–ç›£æ§éƒ¨ç½²

### Docker Compose ç›£æ§å †ç–Š
```yaml
# monitoring-stack.yml
version: '3.8'
services:
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
      - ./monitoring/rosagv_alerts.yml:/etc/prometheus/rosagv_alerts.yml
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--web.enable-lifecycle'
      - '--web.enable-admin-api'

  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin123
    volumes:
      - grafana-storage:/var/lib/grafana
      - ./monitoring/grafana/dashboards:/var/lib/grafana/dashboards
      - ./monitoring/grafana/provisioning:/etc/grafana/provisioning

  alertmanager:
    image: prom/alertmanager:latest
    container_name: alertmanager
    ports:
      - "9093:9093"
    volumes:
      - ./monitoring/alertmanager.yml:/etc/alertmanager/alertmanager.yml

  node-exporter:
    image: prom/node-exporter:latest
    container_name: node-exporter
    ports:
      - "9100:9100"
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    command:
      - '--path.procfs=/host/proc'
      - '--path.rootfs=/rootfs'
      - '--path.sysfs=/host/sys'
      - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'

  cadvisor:
    image: gcr.io/cadvisor/cadvisor:latest
    container_name: cadvisor
    ports:
      - "8080:8080"
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:ro
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
      - /dev/disk/:/dev/disk:ro

volumes:
  grafana-storage:
```

### ç›£æ§éƒ¨ç½²è…³æœ¬
```bash
#!/bin/bash
# setup-monitoring.sh
echo "è¨­å®š RosAGV ç›£æ§ç³»çµ±..."

# 1. å‰µå»ºç›£æ§ç›®éŒ„
mkdir -p monitoring/{prometheus,grafana/{dashboards,provisioning},alertmanager}

# 2. è¤‡è£½é…ç½®æª”æ¡ˆ
cp config/prometheus.yml monitoring/prometheus/
cp config/rosagv_alerts.yml monitoring/prometheus/
cp config/alertmanager.yml monitoring/alertmanager/

# 3. å•Ÿå‹•ç›£æ§å †ç–Š
docker compose -f monitoring-stack.yml up -d

# 4. ç­‰å¾…æœå‹™å•Ÿå‹•
echo "ç­‰å¾…æœå‹™å•Ÿå‹•..."
sleep 30

# 5. é©—è­‰æœå‹™
echo "é©—è­‰ç›£æ§æœå‹™..."
curl -f http://localhost:9090 && echo "âœ… Prometheus OK"
curl -f http://localhost:3000 && echo "âœ… Grafana OK"
curl -f http://localhost:9093 && echo "âœ… AlertManager OK"

echo "ç›£æ§ç³»çµ±è¨­å®šå®Œæˆï¼"
echo "Prometheus: http://localhost:9090"
echo "Grafana: http://localhost:3000 (admin/admin123)"
echo "AlertManager: http://localhost:9093"
```

## ğŸ“ˆ ç›£æ§æœ€ä½³å¯¦è¸

### æŒ‡æ¨™è¨­è¨ˆåŸå‰‡
1. **ç›¸é—œæ€§**: åªæ”¶é›†èˆ‡æ¥­å‹™ç›¸é—œçš„æŒ‡æ¨™
2. **å¯æ“ä½œæ€§**: æŒ‡æ¨™æ‡‰è©²èƒ½æŒ‡å°å…·é«”è¡Œå‹•
3. **åŠæ™‚æ€§**: é‡è¦æŒ‡æ¨™æ‡‰è©²å¯¦æ™‚æ›´æ–°
4. **å¯æ“´å±•æ€§**: ç›£æ§ç³»çµ±æ‡‰è©²èƒ½éš¨ç³»çµ±æˆé•·

### å‘Šè­¦è¨­è¨ˆåŸå‰‡
1. **å¯æ“ä½œçš„å‘Šè­¦**: æ¯å€‹å‘Šè­¦éƒ½æ‡‰è©²æœ‰æ˜ç¢ºçš„è™•ç†æ­¥é©Ÿ
2. **é©ç•¶çš„é–¾å€¼**: é¿å…éå¤šæˆ–éå°‘çš„å‘Šè­¦
3. **åˆ†ç´šå‘Šè­¦**: æŒ‰ç…§åš´é‡ç¨‹åº¦åˆ†ç´šè™•ç†
4. **å‘Šè­¦æŠ‘åˆ¶**: é¿å…å‘Šè­¦é¢¨æš´

---

**ç›¸é—œæ–‡æª”ï¼š**
- [ç³»çµ±è¨ºæ–·](../operations/system-diagnostics.md) - ç›£æ§æ•¸æ“šåˆ†æ
- [æ•ˆèƒ½èª¿å„ª](performance-optimization.md) - ç›£æ§æŒ‡æ¨™æœ€ä½³åŒ–
- [ç¶­è­·æ“ä½œ](../operations/maintenance.md) - åŸºæ–¼ç›£æ§çš„ç¶­è­·
- [æ•…éšœæ’é™¤](../operations/troubleshooting.md) - ç›£æ§å‘Šè­¦è™•ç†