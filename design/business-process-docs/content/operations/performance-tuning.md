# æ•ˆèƒ½èª¿å„ª

## æ¦‚è¿°

RosAGV ç³»çµ±åŸºæ–¼ Zenoh RMW é€šè¨Šæ©Ÿåˆ¶ï¼Œæä¾›é«˜æ•ˆèƒ½çš„è·¨å®¹å™¨å’Œè·¨ç¶²è·¯é€šè¨Šèƒ½åŠ›ã€‚æœ¬æŒ‡å—æ¶µè“‹ Zenoh é€šè¨Šæœ€ä½³åŒ–ã€ç³»çµ±è³‡æºèª¿æ•´å’Œæ•´é«”æ•ˆèƒ½èª¿å„ªç­–ç•¥ã€‚

## Zenoh RMW æ•ˆèƒ½æœ€ä½³åŒ–

### åŸºç¤æ•ˆèƒ½ç‰¹æ€§

#### å»¶é²ç‰¹æ€§åŸºæº–
```
Zenoh RMW å»¶é²æ•ˆèƒ½
â”œâ”€â”€ æœ¬åœ°é€šè¨Š: < 100Î¼s
â”œâ”€â”€ è·¨å®¹å™¨é€šè¨Š: < 1ms
â”œâ”€â”€ è·¨ç¶²è·¯é€šè¨Š: < 10ms (å€åŸŸç¶²è·¯)
â””â”€â”€ å»£åŸŸç¶²è·¯: å–æ±ºæ–¼ç¶²è·¯å»¶é²
```

#### ååé‡ç‰¹æ€§åŸºæº–
```
Zenoh RMW ååé‡æ•ˆèƒ½
â”œâ”€â”€ å°è¨Šæ¯ (< 1KB): > 100k msg/s
â”œâ”€â”€ å¤§è¨Šæ¯ (> 1MB): > 1GB/s (å€åŸŸç¶²è·¯)
â”œâ”€â”€ ä¸¦ç™¼é€£æ¥: > 10k åŒæ™‚é€£æ¥
â””â”€â”€ è¨˜æ†¶é«”ä½¿ç”¨: ä½è¨˜æ†¶é«”ä½”ç”¨è¨­è¨ˆ
```

### Zenoh é…ç½®æœ€ä½³åŒ–

#### ä½å»¶é²é…ç½®
```json5
{
  // ä½å»¶é²æœ€ä½³åŒ–é…ç½®
  "transport": {
    "unicast": {
      "lowlatency": true,           // å•Ÿç”¨ä½å»¶é²æ¨¡å¼
      "qos": {
        "enabled": true             // å•Ÿç”¨ QoS ä¿è­‰
      }
    }
  },
  "routing": {
    "face": {
      "unicast": {
        "accept_timeout": 1000,     // 1ç§’é€£æ¥è¶…æ™‚
        "max_sessions": 1000        // æœ€å¤§æœƒè©±æ•¸
      }
    }
  },
  // ç™¼ç¾æ©Ÿåˆ¶æœ€ä½³åŒ–
  "scouting": {
    "multicast": {
      "enabled": true,
      "address": "224.0.0.224:7446",
      "interface": "auto"
    }
  }
}
```

#### é«˜ååé‡é…ç½®
```json5
{
  // é«˜ååé‡æœ€ä½³åŒ–é…ç½®
  "transport": {
    "unicast": {
      "qos": {
        "enabled": true
      },
      "compression": {
        "enabled": true             // å•Ÿç”¨è³‡æ–™å£“ç¸®
      }
    }
  },
  "plugins": {
    "zenoh-plugin-dds": {
      "shm": {
        "enabled": true             // å•Ÿç”¨å…±äº«è¨˜æ†¶é«”
      }
    }
  },
  // ç·©è¡å€æœ€ä½³åŒ–
  "transport": {
    "unicast": {
      "tx_buffer_size": 65536,      // å‚³é€ç·©è¡å€ 64KB
      "rx_buffer_size": 65536       // æ¥æ”¶ç·©è¡å€ 64KB
    }
  }
}
```

#### å¯é æ€§é…ç½®
```json5
{
  // å¯é æ€§æœ€ä½³åŒ–é…ç½®
  "transport": {
    "unicast": {
      "qos": {
        "enabled": true
      }
    }
  },
  "routing": {
    "face": {
      "unicast": {
        "max_retries": 3,           // æœ€å¤§é‡è©¦æ¬¡æ•¸
        "retry_period": 1000        // é‡è©¦é–“éš” 1ç§’
      }
    }
  },
  // å¿ƒè·³æª¢æ¸¬
  "transport": {
    "unicast": {
      "keep_alive": 30000           // 30ç§’å¿ƒè·³
    }
  }
}
```

### QoS æœ€ä½³åŒ–ç­–ç•¥

#### ROS 2 QoS æ˜ å°„æœ€ä½³åŒ–
```python
from rclpy.qos import QoSProfile, ReliabilityPolicy, DurabilityPolicy, HistoryPolicy

# å³æ™‚æ§åˆ¶æœ€ä½³åŒ– QoS
REALTIME_CONTROL_QOS = QoSProfile(
    reliability=ReliabilityPolicy.BEST_EFFORT,  # ä½å»¶é²å„ªå…ˆ
    durability=DurabilityPolicy.VOLATILE,       # ä¸éœ€è¦æŒä¹…åŒ–
    history=HistoryPolicy.KEEP_LAST,           # åªä¿ç•™æœ€æ–°
    depth=1                                    # æœ€å°ä½‡åˆ—æ·±åº¦
)

# é—œéµè³‡æ–™æœ€ä½³åŒ– QoS
CRITICAL_DATA_QOS = QoSProfile(
    reliability=ReliabilityPolicy.RELIABLE,     # å¯é å‚³è¼¸
    durability=DurabilityPolicy.TRANSIENT_LOCAL, # æœ¬åœ°æŒä¹…åŒ–
    history=HistoryPolicy.KEEP_ALL,            # ä¿ç•™æ‰€æœ‰è³‡æ–™
    depth=100                                  # é©ä¸­ä½‡åˆ—å¤§å°
)

# é«˜é »æ„Ÿæ¸¬å™¨æœ€ä½³åŒ– QoS
HIGH_FREQ_SENSOR_QOS = QoSProfile(
    reliability=ReliabilityPolicy.BEST_EFFORT,
    durability=DurabilityPolicy.VOLATILE,
    history=HistoryPolicy.KEEP_LAST,
    depth=5                                    # å°ä½‡åˆ—ï¼Œé˜²æ­¢ç´¯ç©
)
```

#### æ‡‰ç”¨å ´æ™¯ QoS é¸æ“‡
```python
class RosAGVQoSManager:
    @staticmethod
    def get_agv_status_qos():
        """AGV ç‹€æ…‹ç™¼å¸ƒ QoS"""
        return QoSProfile(
            reliability=ReliabilityPolicy.RELIABLE,
            durability=DurabilityPolicy.TRANSIENT_LOCAL,
            history=HistoryPolicy.KEEP_LAST,
            depth=1
        )
    
    @staticmethod
    def get_sensor_data_qos():
        """æ„Ÿæ¸¬å™¨è³‡æ–™ QoS"""
        return QoSProfile(
            reliability=ReliabilityPolicy.BEST_EFFORT,
            durability=DurabilityPolicy.VOLATILE,
            history=HistoryPolicy.KEEP_LAST,
            depth=10
        )
    
    @staticmethod
    def get_command_qos():
        """æ§åˆ¶æŒ‡ä»¤ QoS"""
        return QoSProfile(
            reliability=ReliabilityPolicy.RELIABLE,
            durability=DurabilityPolicy.VOLATILE,
            history=HistoryPolicy.KEEP_ALL,
            depth=50
        )
```

## ç³»çµ±è³‡æºæœ€ä½³åŒ–

### å®¹å™¨è³‡æºé…ç½®

#### Docker Compose è³‡æºé™åˆ¶
```yaml
# docker-compose.agvc.yml è³‡æºæœ€ä½³åŒ–
services:
  agvc_server:
    deploy:
      resources:
        limits:
          cpus: '4.0'              # CPU é™åˆ¶
          memory: 8G               # è¨˜æ†¶é«”é™åˆ¶
        reservations:
          cpus: '2.0'              # CPU ä¿ç•™
          memory: 4G               # è¨˜æ†¶é«”ä¿ç•™
    environment:
      # JVM è¨˜æ†¶é«”æœ€ä½³åŒ– (å¦‚æœä½¿ç”¨ Java çµ„ä»¶)
      - JAVA_OPTS=-Xmx4g -Xms2g -XX:+UseG1GC
      # Python æœ€ä½³åŒ–
      - PYTHONUNBUFFERED=1
      - PYTHONOPTIMIZE=1
    
  postgres:
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 4G
        reservations:
          cpus: '1.0'
          memory: 2G
    environment:
      # PostgreSQL æ•ˆèƒ½åƒæ•¸
      - POSTGRES_SHARED_BUFFERS=1GB
      - POSTGRES_EFFECTIVE_CACHE_SIZE=3GB
      - POSTGRES_WORK_MEM=16MB
```

#### ç³»çµ±æ ¸å¿ƒåƒæ•¸èª¿æ•´
```bash
# /etc/sysctl.conf ç¶²è·¯æœ€ä½³åŒ–
# TCP ç·©è¡å€æœ€ä½³åŒ–
net.core.rmem_max = 268435456          # 256MB æ¥æ”¶ç·©è¡å€
net.core.wmem_max = 268435456          # 256MB ç™¼é€ç·©è¡å€
net.ipv4.tcp_rmem = 4096 87380 268435456
net.ipv4.tcp_wmem = 4096 65536 268435456

# é€£æ¥æ•¸æœ€ä½³åŒ–
net.core.somaxconn = 65535             # æœ€å¤§é€£æ¥ä½‡åˆ—
net.ipv4.tcp_max_syn_backlog = 65535   # SYN ä½‡åˆ—å¤§å°
net.core.netdev_max_backlog = 5000     # ç¶²è·¯è¨­å‚™ä½‡åˆ—

# æ‡‰ç”¨ç«‹å³ç”Ÿæ•ˆ
sudo sysctl -p
```

### PostgreSQL æ•ˆèƒ½èª¿æ•´

#### æ ¸å¿ƒé…ç½®æœ€ä½³åŒ–
```sql
-- postgresql.conf æ•ˆèƒ½åƒæ•¸
-- è¨˜æ†¶é«”é…ç½®
shared_buffers = 1GB                    -- å…±äº«ç·©è¡å€
effective_cache_size = 3GB              -- æœ‰æ•ˆå¿«å–å¤§å°
work_mem = 16MB                         -- å·¥ä½œè¨˜æ†¶é«”
maintenance_work_mem = 256MB            -- ç¶­è­·è¨˜æ†¶é«”

-- å¯«å…¥æœ€ä½³åŒ–
checkpoint_completion_target = 0.9      -- æª¢æŸ¥é»å®Œæˆç›®æ¨™
wal_buffers = 16MB                      -- WAL ç·©è¡å€
max_wal_size = 2GB                      -- WAL æœ€å¤§å¤§å°

-- é€£æ¥æœ€ä½³åŒ–
max_connections = 200                   -- æœ€å¤§é€£æ¥æ•¸

-- æŸ¥è©¢æœ€ä½³åŒ–
random_page_cost = 1.1                  -- SSD éš¨æ©Ÿè®€å–æˆæœ¬
effective_io_concurrency = 200          -- I/O ä¸¦ç™¼åº¦
```

#### ç´¢å¼•ç­–ç•¥æœ€ä½³åŒ–
```sql
-- è‡ªå‹•å»ºç«‹æ•ˆèƒ½ç´¢å¼•
CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_agv_status_location 
ON agvs(status, current_location_id);

CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_task_priority_status_created 
ON tasks(priority DESC, status, created_at);

CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_carrier_rack_status 
ON carrier(rack_id, status);

-- éƒ¨åˆ†ç´¢å¼•æœ€ä½³åŒ–
CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_pending_tasks 
ON tasks(priority DESC, created_at) 
WHERE status = 'pending';

-- è¡¨é”å¼ç´¢å¼•
CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_location_coordinates 
ON location((x + y));  -- ç”¨æ–¼è·é›¢è¨ˆç®—
```

#### PostgreSQL æ•ˆèƒ½ç›£æ§
```sql
-- æª¢æŸ¥æ´»èºé€£æ¥å’Œé–å®šæƒ…æ³
SELECT 
    pid,
    usename,
    application_name,
    client_addr,
    state,
    query_start,
    query
FROM pg_stat_activity 
WHERE state = 'active'
ORDER BY query_start;

-- æª¢æŸ¥è³‡æ–™åº«çµ±è¨ˆè³‡è¨Š (å«è©³ç´°èªªæ˜)
SELECT 
    datname,                           -- è³‡æ–™åº«åç¨±
    numbackends as active_connections, -- ç•¶å‰æ´»èºé€£æ¥æ•¸
    xact_commit,                       -- æäº¤çš„äº¤æ˜“ç¸½æ•¸
    xact_rollback,                     -- å›æ»¾çš„äº¤æ˜“ç¸½æ•¸  
    blks_read,                         -- å¾ç£ç¢Ÿè®€å–çš„å€å¡Šæ•¸ (æ…¢)
    blks_hit,                          -- å¾å¿«å–å‘½ä¸­çš„å€å¡Šæ•¸ (å¿«)
    temp_files,                        -- å»ºç«‹çš„è‡¨æ™‚æª”æ¡ˆæ•¸
    temp_bytes,                        -- è‡¨æ™‚æª”æ¡ˆä½¿ç”¨çš„ä½å…ƒçµ„æ•¸
    -- è¨ˆç®—å¿«å–å‘½ä¸­ç‡ (é‡è¦æ•ˆèƒ½æŒ‡æ¨™)
    ROUND(100.0 * blks_hit / NULLIF(blks_hit + blks_read, 0), 2) as cache_hit_ratio,
    -- è¨ˆç®—å›æ»¾ç‡ (ç©©å®šæ€§æŒ‡æ¨™)  
    ROUND(100.0 * xact_rollback / NULLIF(xact_commit + xact_rollback, 0), 2) as rollback_ratio
FROM pg_stat_database 
WHERE datname = 'agvc';

-- æª¢æŸ¥è¡¨ä½¿ç”¨çµ±è¨ˆ (å«è©³ç´°èªªæ˜)
SELECT 
    schemaname,                        -- ç¶±è¦åç¨±
    tablename,                         -- è¡¨æ ¼åç¨±
    seq_scan,                          -- é †åºæƒææ¬¡æ•¸ (å…¨è¡¨æƒæï¼Œæ•ˆèƒ½è¼ƒå·®)
    seq_tup_read,                      -- é †åºæƒæè®€å–çš„è³‡æ–™åˆ—æ•¸
    idx_scan,                          -- ç´¢å¼•æƒææ¬¡æ•¸ (æ•ˆèƒ½è¼ƒå¥½)
    idx_tup_fetch,                     -- ç´¢å¼•æƒæå–å¾—çš„è³‡æ–™åˆ—æ•¸
    n_tup_ins,                         -- æ’å…¥çš„è³‡æ–™åˆ—æ•¸
    n_tup_upd,                         -- æ›´æ–°çš„è³‡æ–™åˆ—æ•¸
    n_tup_del,                         -- åˆªé™¤çš„è³‡æ–™åˆ—æ•¸
    -- è¨ˆç®—ç´¢å¼•ä½¿ç”¨ç‡ (é‡è¦æ•ˆèƒ½æŒ‡æ¨™)
    CASE 
        WHEN (seq_scan + idx_scan) > 0 
        THEN ROUND(100.0 * idx_scan / (seq_scan + idx_scan), 2) 
        ELSE 0 
    END as index_usage_ratio
FROM pg_stat_user_tables
ORDER BY seq_scan DESC;

-- ğŸ’¡ è¡¨æ ¼æ•ˆèƒ½åˆ†æèªªæ˜ï¼š
-- seq_scan é«˜ = ç¶“å¸¸å…¨è¡¨æƒæ (éœ€è¦å»ºç«‹ç´¢å¼•)
-- idx_scan é«˜ = ç´¢å¼•ä½¿ç”¨è‰¯å¥½ (æ•ˆèƒ½ä½³)
-- index_usage_ratio > 95% = ç´¢å¼•ä½¿ç”¨ç‡å„ªç§€
-- index_usage_ratio < 80% = éœ€è¦æª¢æŸ¥ç´¢å¼•è¨­è¨ˆ

-- æª¢æŸ¥ç´¢å¼•ä½¿ç”¨æ•ˆç‡
SELECT 
    schemaname,
    tablename,
    indexname,
    idx_scan,
    idx_tup_read,
    idx_tup_fetch
FROM pg_stat_user_indexes
WHERE idx_scan = 0  -- æ‰¾å‡ºæœªä½¿ç”¨çš„ç´¢å¼•
ORDER BY schemaname, tablename;
```

### ROS 2 ç¯€é»æœ€ä½³åŒ–

#### ç¯€é»æ•ˆèƒ½èª¿æ•´
```python
import rclpy
from rclpy.executors import MultiThreadedExecutor
from rclpy.callback_groups import ReentrantCallbackGroup, MutuallyExclusiveCallbackGroup

class OptimizedAGVNode(Node):
    def __init__(self):
        super().__init__('optimized_agv_node')
        
        # å›èª¿ç¾¤çµ„æœ€ä½³åŒ–
        self.reentrant_group = ReentrantCallbackGroup()
        self.exclusive_group = MutuallyExclusiveCallbackGroup()
        
        # é«˜é »æ„Ÿæ¸¬å™¨è¨‚é–± (ä¸¦è¡Œè™•ç†)
        self.sensor_subscription = self.create_subscription(
            SensorMsg, 'sensor_data', 
            self.sensor_callback,
            HIGH_FREQ_SENSOR_QOS,
            callback_group=self.reentrant_group
        )
        
        # æ§åˆ¶æŒ‡ä»¤è¨‚é–± (åºåˆ—è™•ç†)
        self.command_subscription = self.create_subscription(
            CommandMsg, 'agv_commands',
            self.command_callback,
            CRITICAL_DATA_QOS,
            callback_group=self.exclusive_group
        )
        
        # ç‹€æ…‹ç™¼å¸ƒå™¨æœ€ä½³åŒ–
        self.status_publisher = self.create_publisher(
            AGVStatus, 'agv_status',
            self.get_agv_status_qos()
        )
        
        # å®šæ™‚å™¨æœ€ä½³åŒ– (æ¸›å°‘ç³»çµ±èª¿ç”¨)
        self.status_timer = self.create_timer(
            0.1,  # 10Hz ç‹€æ…‹ç™¼å¸ƒ
            self.publish_status,
            callback_group=self.reentrant_group
        )
    
    def sensor_callback(self, msg):
        """æ„Ÿæ¸¬å™¨å›èª¿ - éé˜»å¡è™•ç†"""
        # ä½¿ç”¨åŸ·è¡Œç·’æ± è™•ç†è€—æ™‚æ“ä½œ
        self.executor.create_task(self.process_sensor_data(msg))
    
    async def process_sensor_data(self, msg):
        """ç•°æ­¥è™•ç†æ„Ÿæ¸¬å™¨è³‡æ–™"""
        # éé˜»å¡çš„è³‡æ–™è™•ç†é‚è¼¯
        pass
```

#### åŸ·è¡Œå™¨æœ€ä½³åŒ–
```python
def main():
    rclpy.init()
    
    # å¤šåŸ·è¡Œç·’åŸ·è¡Œå™¨æœ€ä½³åŒ–
    executor = MultiThreadedExecutor(num_threads=4)
    
    # å»ºç«‹æœ€ä½³åŒ–ç¯€é»
    node = OptimizedAGVNode()
    executor.add_node(node)
    
    try:
        # ä½¿ç”¨ executor é€²è¡Œæœ€ä½³åŒ–èª¿åº¦
        executor.spin()
    finally:
        executor.shutdown()
        node.destroy_node()
        rclpy.shutdown()
```

## ç¶²è·¯æœ€ä½³åŒ–

### Zenoh Router ç¶²è·¯èª¿æ•´

#### è·¯ç”±å™¨é…ç½®æœ€ä½³åŒ–
```json5
{
  // ç¶²è·¯æœ€ä½³åŒ–é…ç½®
  "listen": {
    "endpoints": [
      "tcp/0.0.0.0:7447"
    ],
    "timeout": 5000,                    // 5ç§’é€£æ¥è¶…æ™‚
    "backlog": 1024                     // é€£æ¥ä½‡åˆ—å¤§å°
  },
  
  // å¤šæ’­ç™¼ç¾æœ€ä½³åŒ–
  "scouting": {
    "multicast": {
      "enabled": true,
      "address": "224.0.0.224:7446",
      "interface": "auto",
      "ttl": 1,                         // TTL æœ€ä½³åŒ–
      "enabled": true
    }
  },
  
  // è·¯ç”±æ•ˆèƒ½æœ€ä½³åŒ–
  "routing": {
    "face": {
      "unicast": {
        "accept_timeout": 5000,
        "max_sessions": 2000,           // å¢åŠ æœ€å¤§æœƒè©±æ•¸
        "max_links": 100                // æœ€å¤§é€£çµæ•¸
      }
    }
  }
}
```

### é˜²ç«ç‰†å’Œç¶²è·¯è¨­å®š

#### iptables æœ€ä½³åŒ–
```bash
#!/bin/bash
# zenoh-firewall-optimize.sh

# Zenoh ç«¯å£æœ€ä½³åŒ–
iptables -A INPUT -p tcp --dport 7447 -m conntrack --ctstate NEW -m limit --limit 1000/sec -j ACCEPT
iptables -A INPUT -p udp --dport 7446 -j ACCEPT  # å¤šæ’­ç™¼ç¾

# é€£æ¥è¿½è¹¤æœ€ä½³åŒ–
echo 'net.netfilter.nf_conntrack_max = 1048576' >> /etc/sysctl.conf
echo 'net.netfilter.nf_conntrack_tcp_timeout_established = 7200' >> /etc/sysctl.conf

# TCP æœ€ä½³åŒ–
echo 'net.ipv4.tcp_congestion_control = bbr' >> /etc/sysctl.conf
echo 'net.core.default_qdisc = fq' >> /etc/sysctl.conf

sysctl -p
```

## æ‡‰ç”¨ç¨‹å¼æœ€ä½³åŒ–

### FastAPI æ•ˆèƒ½èª¿æ•´

#### Web API æœ€ä½³åŒ–
```python
from fastapi import FastAPI, Depends
from fastapi.middleware.gzip import GZipMiddleware
from fastapi.middleware.cors import CORSMiddleware
import uvicorn

# FastAPI æ‡‰ç”¨æœ€ä½³åŒ–
app = FastAPI(
    title="RosAGV API",
    docs_url="/docs",
    redoc_url="/redoc",
    openapi_url="/openapi.json"
)

# ä¸­é–“ä»¶æœ€ä½³åŒ–
app.add_middleware(GZipMiddleware, minimum_size=1000)  # å£“ç¸®ä¸­é–“ä»¶
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# è³‡æ–™åº«é€£ç·šæ± æœ€ä½³åŒ–
from sqlalchemy.pool import QueuePool

DATABASE_CONFIG = {
    "pool_size": 20,          # é€£ç·šæ± å¤§å°
    "max_overflow": 30,       # æœ€å¤§æº¢å‡ºé€£ç·š
    "pool_timeout": 30,       # é€£ç·šè¶…æ™‚
    "pool_recycle": 3600,     # é€£ç·šå›æ”¶æ™‚é–“
    "pool_pre_ping": True,    # é€£ç·šæª¢æŸ¥
}

# ç•°æ­¥æ“ä½œæœ€ä½³åŒ–
@app.get("/agvs/status")
async def get_agv_status():
    """æœ€ä½³åŒ–çš„ AGV ç‹€æ…‹æŸ¥è©¢"""
    async with get_db() as session:
        # ä½¿ç”¨ç´¢å¼•æœ€ä½³åŒ–æŸ¥è©¢
        result = await session.exec(
            select(AGV)
            .where(AGV.status.in_(["idle", "busy"]))
            .options(selectinload(AGV.current_location))  # é è¼‰å…¥é—œè¯
        )
        return result.all()

# Uvicorn ä¼ºæœå™¨æœ€ä½³åŒ–
if __name__ == "__main__":
    uvicorn.run(
        "main:app",
        host="0.0.0.0",
        port=8000,
        workers=4,              # å·¥ä½œé€²ç¨‹æ•¸
        worker_class="uvicorn.workers.UvicornWorker",
        loop="uvloop",          # é«˜æ•ˆèƒ½äº‹ä»¶å¾ªç’°
        http="httptools",       # é«˜æ•ˆèƒ½ HTTP è§£æå™¨
        access_log=False,       # ç”Ÿç”¢ç’°å¢ƒé—œé–‰å­˜å–æ—¥èªŒ
        reload=False            # ç”Ÿç”¢ç’°å¢ƒé—œé–‰è‡ªå‹•é‡è¼‰
    )
```

### å¿«å–ç­–ç•¥

#### Redis å¿«å–æ•´åˆ
```python
import redis.asyncio as redis
from functools import wraps
import json
import pickle

class RosAGVCache:
    def __init__(self):
        self.redis_client = redis.Redis(
            host='localhost',
            port=6379,
            db=0,
            encoding='utf-8',
            decode_responses=False,
            socket_connect_timeout=5,
            socket_timeout=5,
            retry_on_timeout=True,
            health_check_interval=30
        )
    
    async def cache_agv_status(self, agv_id: int, status_data: dict, expire: int = 60):
        """å¿«å– AGV ç‹€æ…‹"""
        key = f"agv_status:{agv_id}"
        await self.redis_client.setex(
            key, 
            expire, 
            json.dumps(status_data, default=str)
        )
    
    async def get_cached_agv_status(self, agv_id: int) -> dict:
        """å–å¾—å¿«å–çš„ AGV ç‹€æ…‹"""
        key = f"agv_status:{agv_id}"
        data = await self.redis_client.get(key)
        if data:
            return json.loads(data)
        return None

# å¿«å–è£é£¾å™¨
def cache_result(expire: int = 300):
    def decorator(func):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            # ç”Ÿæˆå¿«å–éµ
            cache_key = f"{func.__name__}:{hash(str(args) + str(kwargs))}"
            
            # å˜—è©¦å¾å¿«å–å–å¾—
            cached = await cache.redis_client.get(cache_key)
            if cached:
                return pickle.loads(cached)
            
            # åŸ·è¡Œå‡½æ•¸ä¸¦å¿«å–çµæœ
            result = await func(*args, **kwargs)
            await cache.redis_client.setex(
                cache_key, 
                expire, 
                pickle.dumps(result)
            )
            return result
        return wrapper
    return decorator

# ä½¿ç”¨å¿«å–çš„ç¯„ä¾‹
@cache_result(expire=600)  # å¿«å– 10 åˆ†é˜
async def get_available_agvs(agv_type: str = None):
    """å–å¾—å¯ç”¨ AGV (å«å¿«å–)"""
    # åŸ·è¡Œè³‡æ–™åº«æŸ¥è©¢
    return await agv_crud.get_available_agvs(session, agv_type)
```

## ç›£æ§å’Œè¨ºæ–·

### æ•ˆèƒ½ç›£æ§æŒ‡æ¨™

#### ç³»çµ±æ•ˆèƒ½ç›£æ§
```python
import psutil
import time
from dataclasses import dataclass
from typing import Dict, List

@dataclass
class SystemMetrics:
    timestamp: float
    cpu_percent: float
    memory_percent: float
    disk_io: Dict
    network_io: Dict
    zenoh_connections: int

class PerformanceMonitor:
    def __init__(self):
        self.metrics_history: List[SystemMetrics] = []
        
    async def collect_metrics(self) -> SystemMetrics:
        """æ”¶é›†ç³»çµ±æ•ˆèƒ½æŒ‡æ¨™"""
        
        # CPU ä½¿ç”¨ç‡
        cpu_percent = psutil.cpu_percent(interval=1)
        
        # è¨˜æ†¶é«”ä½¿ç”¨ç‡
        memory = psutil.virtual_memory()
        memory_percent = memory.percent
        
        # ç£ç¢Ÿ I/O
        disk_io = psutil.disk_io_counters()._asdict()
        
        # ç¶²è·¯ I/O
        network_io = psutil.net_io_counters()._asdict()
        
        # Zenoh é€£æ¥æ•¸ (é€éç«¯å£æª¢æŸ¥)
        zenoh_connections = len([
            conn for conn in psutil.net_connections() 
            if conn.laddr.port == 7447 and conn.status == 'ESTABLISHED'
        ])
        
        metrics = SystemMetrics(
            timestamp=time.time(),
            cpu_percent=cpu_percent,
            memory_percent=memory_percent,
            disk_io=disk_io,
            network_io=network_io,
            zenoh_connections=zenoh_connections
        )
        
        # ä¿ç•™æœ€è¿‘ 1000 ç­†è¨˜éŒ„
        self.metrics_history.append(metrics)
        if len(self.metrics_history) > 1000:
            self.metrics_history.pop(0)
            
        return metrics
    
    def get_performance_summary(self) -> Dict:
        """å–å¾—æ•ˆèƒ½æ‘˜è¦"""
        if not self.metrics_history:
            return {}
            
        recent_metrics = self.metrics_history[-60:]  # æœ€è¿‘ 60 ç­†
        
        return {
            "avg_cpu": sum(m.cpu_percent for m in recent_metrics) / len(recent_metrics),
            "avg_memory": sum(m.memory_percent for m in recent_metrics) / len(recent_metrics),
            "max_zenoh_connections": max(m.zenoh_connections for m in recent_metrics),
            "current_zenoh_connections": recent_metrics[-1].zenoh_connections if recent_metrics else 0
        }
```

### Zenoh æ•ˆèƒ½ç›£æ§

#### Zenoh é€šè¨Šè¨ºæ–·
```bash
#!/bin/bash
# zenoh-performance-check.sh

echo "ğŸ” Zenoh æ•ˆèƒ½è¨ºæ–·é–‹å§‹..."

# æª¢æŸ¥ Zenoh é€²ç¨‹
echo "ğŸ“Š Zenoh é€²ç¨‹ç‹€æ…‹:"
ps aux | grep zenoh | grep -v grep

# æª¢æŸ¥ Zenoh ç«¯å£
echo "ğŸŒ Zenoh ç«¯å£é€£æ¥:"
ss -tuln | grep 7447
ss -s | grep tcp

# æª¢æŸ¥ç¶²è·¯æ•ˆèƒ½
echo "ğŸ“ˆ ç¶²è·¯ä»‹é¢çµ±è¨ˆ:"
cat /proc/net/dev | grep -E "(eth0|wlan0|docker0)"

# æª¢æŸ¥ ROS 2 ä¸»é¡Œé »ç‡
echo "ğŸ”„ ROS 2 ä¸»é¡Œæ•ˆèƒ½:"
timeout 10 ros2 topic hz /agv_status 2>/dev/null || echo "ä¸»é¡Œä¸å¯ç”¨"

# æª¢æŸ¥è¨˜æ†¶é«”ä½¿ç”¨
echo "ğŸ’¾ è¨˜æ†¶é«”ä½¿ç”¨ç‹€æ³:"
free -h
echo "ğŸ” Zenoh è¨˜æ†¶é«”ä½¿ç”¨:"
pmap $(pgrep zenohd) | tail -1

echo "âœ… Zenoh æ•ˆèƒ½è¨ºæ–·å®Œæˆ"
```

### è‡ªå‹•åŒ–æ•ˆèƒ½èª¿æ•´

#### è‡ªé©æ‡‰ QoS èª¿æ•´
```python
class AdaptiveQoSManager:
    def __init__(self):
        self.latency_history = []
        self.message_loss_rate = 0.0
        
    async def measure_latency(self, topic_name: str) -> float:
        """æ¸¬é‡ä¸»é¡Œå»¶é²"""
        start_time = time.time()
        
        # ç™¼é€æ¸¬è©¦è¨Šæ¯ä¸¦ç­‰å¾…å›æ‡‰
        test_msg = TestMessage(timestamp=start_time)
        await self.test_publisher.publish(test_msg)
        
        # ç­‰å¾…å›æ‡‰ (ç°¡åŒ–å¯¦ä½œ)
        await asyncio.sleep(0.001)  # 1ms é ä¼°å»¶é²
        
        latency = time.time() - start_time
        self.latency_history.append(latency)
        
        # ä¿ç•™æœ€è¿‘ 100 ç­†è¨˜éŒ„
        if len(self.latency_history) > 100:
            self.latency_history.pop(0)
            
        return latency
    
    def get_adaptive_qos(self, topic_type: str) -> QoSProfile:
        """æ ¹æ“šç¶²è·¯ç‹€æ³èª¿æ•´ QoS"""
        avg_latency = sum(self.latency_history) / len(self.latency_history) if self.latency_history else 0.001
        
        if avg_latency < 0.001:  # < 1msï¼Œç¶²è·¯è‰¯å¥½
            if topic_type == "sensor":
                return QoSProfile(
                    reliability=ReliabilityPolicy.BEST_EFFORT,
                    history=HistoryPolicy.KEEP_LAST,
                    depth=1
                )
        elif avg_latency > 0.01:  # > 10msï¼Œç¶²è·¯æ“å¡
            if topic_type == "sensor":
                return QoSProfile(
                    reliability=ReliabilityPolicy.BEST_EFFORT,
                    history=HistoryPolicy.KEEP_LAST,
                    depth=5  # å¢åŠ ç·©è¡
                )
        
        # é è¨­ QoS
        return QoSProfile(
            reliability=ReliabilityPolicy.RELIABLE,
            history=HistoryPolicy.KEEP_LAST,
            depth=10
        )
```

## æ•…éšœæ’é™¤

### æ•ˆèƒ½å•é¡Œè¨ºæ–·

#### å¸¸è¦‹æ•ˆèƒ½ç“¶é ¸
```bash
# 1. Zenoh é€£æ¥å•é¡Œè¨ºæ–·
r zenoh-check                          # æª¢æŸ¥ Zenoh ç‹€æ…‹
netstat -tuln | grep 7447             # æª¢æŸ¥ç«¯å£ç›£è½

# 2. è³‡æ–™åº«æ•ˆèƒ½è¨ºæ–·
# æª¢æŸ¥æ´»èºé€£æ¥æ•¸
docker compose -f docker-compose.agvc.yml exec postgres psql -U agvc -d agvc -c "SELECT count(*) FROM pg_stat_activity WHERE state = 'active';"

# æª¢æŸ¥è³‡æ–™åº«å¤§å°
docker compose -f docker-compose.agvc.yml exec postgres psql -U agvc -d agvc -c "SELECT pg_size_pretty(pg_database_size('agvc')) as db_size;"

# æª¢æŸ¥è¡¨å¤§å°çµ±è¨ˆ
docker compose -f docker-compose.agvc.yml exec postgres psql -U agvc -d agvc -c "SELECT schemaname, tablename, pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) as size FROM pg_tables WHERE schemaname = 'public' ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC LIMIT 10;"

# 3. ç³»çµ±è³‡æºè¨ºæ–·
top -p $(pgrep zenohd)                # Zenoh é€²ç¨‹è³‡æº
docker stats                         # å®¹å™¨è³‡æºä½¿ç”¨

# 4. ç¶²è·¯æ•ˆèƒ½è¨ºæ–·
iftop -i eth0                         # ç¶²è·¯æµé‡ç›£æ§
ss -i                                 # TCP è³‡è¨Šè©³ç´°
```

#### è‡ªå‹•æ•ˆèƒ½èª¿æ•´è…³æœ¬
```bash
#!/bin/bash
# auto-performance-tune.sh

LOG_FILE="/tmp/performance-tune.log"

log_message() {
    echo "$(date '+%Y-%m-%d %H:%M:%S') $1" | tee -a $LOG_FILE
}

# æª¢æŸ¥ CPU ä½¿ç”¨ç‡
CPU_USAGE=$(top -bn1 | grep "Cpu(s)" | awk '{print $2}' | sed 's/%us,//')
if (( $(echo "$CPU_USAGE > 80" | bc -l) )); then
    log_message "âš ï¸ é«˜ CPU ä½¿ç”¨ç‡: $CPU_USAGE%"
    
    # é™ä½ ROS 2 ç¯€é»é »ç‡
    pkill -SIGUSR1 agv_node  # ç™¼é€ä¿¡è™Ÿé™é »
fi

# æª¢æŸ¥è¨˜æ†¶é«”ä½¿ç”¨ç‡
MEM_USAGE=$(free | grep Mem | awk '{printf("%.1f"), $3/$2 * 100.0}')
if (( $(echo "$MEM_USAGE > 85" | bc -l) )); then
    log_message "âš ï¸ é«˜è¨˜æ†¶é«”ä½¿ç”¨ç‡: $MEM_USAGE%"
    
    # æ¸…ç†å¿«å–
    echo 1 > /proc/sys/vm/drop_caches
fi

# æª¢æŸ¥ Zenoh é€£æ¥æ•¸
ZENOH_CONNECTIONS=$(ss -tuln | grep 7447 | wc -l)
if [ $ZENOH_CONNECTIONS -eq 0 ]; then
    log_message "âŒ Zenoh Router æœªé‹è¡Œï¼Œå˜—è©¦é‡å•Ÿ"
    systemctl restart zenoh-router
fi

log_message "âœ… æ•ˆèƒ½æª¢æŸ¥å®Œæˆ"
```

## ç›¸é—œæ–‡æª”

- [Zenoh é€šè¨Š](../technical-details/zenoh-communication.md) - Zenoh RMW è©³ç´°é…ç½®
- [ç³»çµ±æ¶æ§‹](../system-architecture/dual-environment.md) - é›™ç’°å¢ƒæ¶æ§‹è¨­è¨ˆ
- [è³‡æ–™åº«è¨­è¨ˆ](../technical-details/database-design.md) - è³‡æ–™åº«æœ€ä½³åŒ–
- [ç›£æ§è¨­å®š](../technical-details/monitoring-setup.md) - ç³»çµ±ç›£æ§é…ç½®
- [æ•…éšœæ’é™¤](troubleshooting.md) - å•é¡Œè¨ºæ–·å’Œè§£æ±º